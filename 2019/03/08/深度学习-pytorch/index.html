<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="[TOC] https://ptorch.com/news/45.html 基础 https://blog.csdn.net/Tan915730/article/details/78954482 函数名下划线https://blog.csdn.net/qq_27261889/article/details/86777230 函数，数据类型查询https://blog.csdn.net/zzulp/">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习-pytorch">
<meta property="og:url" content="http://yoursite.com/2019/03/08/深度学习-pytorch/index.html">
<meta property="og:site_name" content="Chenxr&#39;s blogs">
<meta property="og:description" content="[TOC] https://ptorch.com/news/45.html 基础 https://blog.csdn.net/Tan915730/article/details/78954482 函数名下划线https://blog.csdn.net/qq_27261889/article/details/86777230 函数，数据类型查询https://blog.csdn.net/zzulp/">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-05-25T17:10:24.246Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习-pytorch">
<meta name="twitter:description" content="[TOC] https://ptorch.com/news/45.html 基础 https://blog.csdn.net/Tan915730/article/details/78954482 函数名下划线https://blog.csdn.net/qq_27261889/article/details/86777230 函数，数据类型查询https://blog.csdn.net/zzulp/">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/03/08/深度学习-pytorch/">





  <title>深度学习-pytorch | Chenxr's blogs</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chenxr's blogs</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/深度学习-pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">深度学习-pytorch</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:44:59+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>[TOC]</p>
<p><a href="https://ptorch.com/news/45.html" target="_blank" rel="noopener">https://ptorch.com/news/45.html</a></p>
<h1>基础</h1>
<p><a href="https://blog.csdn.net/Tan915730/article/details/78954482" target="_blank" rel="noopener">https://blog.csdn.net/Tan915730/article/details/78954482</a></p>
<p>函数名下划线<a href="https://blog.csdn.net/qq_27261889/article/details/86777230" target="_blank" rel="noopener">https://blog.csdn.net/qq_27261889/article/details/86777230</a></p>
<p>函数，数据类型查询<a href="https://blog.csdn.net/zzulp/article/details/80573331" target="_blank" rel="noopener">https://blog.csdn.net/zzulp/article/details/80573331</a></p>
<h2 id="帮助文档"><a class="header-anchor" href="#帮助文档">¶</a>帮助文档</h2>
<p><a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">https://pytorch.org/docs/stable/index.html</a></p>
<h2 id="类型及类型转换"><a class="header-anchor" href="#类型及类型转换">¶</a>类型及类型转换</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">print(inputs.dtype) <span class="comment"># float32</span></span><br></pre></td></tr></table></figure>
<h2 id="运行模型"><a class="header-anchor" href="#运行模型">¶</a>运行模型</h2>
<p>直接运行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">model = nn.Sigmoid()</span><br><span class="line">outputs = model(inputs)</span><br><span class="line">print(outputs)</span><br><span class="line"><span class="comment"># tensor([[[[0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820]]]])</span></span><br></pre></td></tr></table></figure>
<p>通过继承nn.Module，重载__init__和forward</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sig</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__() </span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.sigmoid(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">model = sig()</span><br><span class="line">outputs = model(inputs)</span><br><span class="line">print(outputs)</span><br><span class="line"><span class="comment"># tensor([[[[0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820]]]])</span></span><br></pre></td></tr></table></figure>
<h2 id="cpu与gpu"><a class="header-anchor" href="#cpu与gpu">¶</a>cpu与gpu</h2>
<p><a href="https://blog.csdn.net/liulina603/article/details/80180355" target="_blank" rel="noopener">https://blog.csdn.net/liulina603/article/details/80180355</a></p>
<p><a href="https://ptorch.com/news/160.html" target="_blank" rel="noopener">https://ptorch.com/news/160.html</a></p>
<h1>数据集</h1>
<h2 id="dataset-dataloader"><a class="header-anchor" href="#dataset-dataloader">¶</a>Dataset &amp;&amp; Dataloader</h2>
<p>torch.utils.data.Dataset</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">trainset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#定义好 image 的路径</span></span><br><span class="line">        self.images = file_train</span><br><span class="line">        self.target = number_train</span><br><span class="line">        self.loader = loader</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        fn = self.images[index]</span><br><span class="line">        img = self.loader(fn)</span><br><span class="line">        target = self.target[index]</span><br><span class="line">        <span class="keyword">return</span> img,target</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.images)</span><br></pre></td></tr></table></figure>
<p>torch.utils.data.Dataloader</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">32</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(</span><br><span class="line">            mean=np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]),</span><br><span class="line">            std=np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])),</span><br><span class="line">    ])</span><br><span class="line"><span class="comment"># prepare dataset by ImageFolder, data should be classified by directory</span></span><br><span class="line">train_set = torchvision.datasets.ImageFolder(root = <span class="string">'./mnist/train'</span>, transform = transform)</span><br><span class="line"><span class="comment"># print(train_set[0][0])</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size = <span class="number">32</span>, shuffle = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train_loader:</span><br><span class="line">    print(i[<span class="number">0</span>].shape) <span class="comment"># torch.Size([32, 3, 32, 32])</span></span><br><span class="line">    print(i[<span class="number">1</span>].shape) <span class="comment"># torch.Size([32]) </span></span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"><span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">    print(data.shape) <span class="comment"># 同上</span></span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h1>各种处理/转换</h1>
<h2 id="view"><a class="header-anchor" href="#view">¶</a>view</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">img_pil =  Image.open(<span class="string">'./mnist/test/0/mnist_test_10.png'</span>)</span><br><span class="line">img_pil = img_pil.convert(<span class="string">'RGB'</span>)</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">32</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(</span><br><span class="line">        mean=np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]),</span><br><span class="line">        std=np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])),</span><br><span class="line">])</span><br><span class="line">img_pil = transform(img_pil)</span><br><span class="line">print(img_pil.shape) <span class="comment"># 3 32 32</span></span><br><span class="line">img_pil = img_pil.view(<span class="number">1</span>,img_pil.size(<span class="number">0</span>), img_pil.size(<span class="number">1</span>), img_pil.size(<span class="number">2</span>))</span><br><span class="line">print(img_pil.shape) <span class="comment"># 1 3 32 32</span></span><br></pre></td></tr></table></figure>
<h2 id="transforms"><a class="header-anchor" href="#transforms">¶</a>transforms</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">32</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(</span><br><span class="line">    	mean=np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]),</span><br><span class="line">        std=np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])),</span><br><span class="line">])</span><br><span class="line">img_pil =  Image.open(<span class="string">'./mnist/test/0/mnist_test_10.png'</span>)</span><br><span class="line">img_pil = img_pil.convert(<span class="string">'RGB'</span>)</span><br><span class="line">img_pil = transform(img_pil)</span><br></pre></td></tr></table></figure>
<h2 id="squeeze"><a class="header-anchor" href="#squeeze">¶</a>squeeze</h2>
<h2 id="unsqueeze"><a class="header-anchor" href="#unsqueeze">¶</a>unsqueeze</h2>
<h1>基本运算</h1>
<p><a href="https://blog.csdn.net/th_num/article/details/80783037" target="_blank" rel="noopener">https://blog.csdn.net/th_num/article/details/80783037</a></p>
<h2 id="max"><a class="header-anchor" href="#max">¶</a>max</h2>
<h2 id="eq"><a class="header-anchor" href="#eq">¶</a>eq</h2>
<h2 id="abs"><a class="header-anchor" href="#abs">¶</a>abs</h2>
<h2 id="sin"><a class="header-anchor" href="#sin">¶</a>sin</h2>
<h2 id="mean"><a class="header-anchor" href="#mean">¶</a>mean</h2>
<h1>深度学习运算</h1>
<h2 id="层"><a class="header-anchor" href="#层">¶</a>层</h2>
<h3 id="卷积层"><a class="header-anchor" href="#卷积层">¶</a>卷积层</h3>
<h4 id="conv-1d-2d-3d"><a class="header-anchor" href="#conv-1d-2d-3d">¶</a>Conv（1d/2d/3d）</h4>
<h4 id="convtranspose-1d-2d-3d"><a class="header-anchor" href="#convtranspose-1d-2d-3d">¶</a>ConvTranspose（1d/2d/3d）</h4>
<h4 id="unfold"><a class="header-anchor" href="#unfold">¶</a>Unfold</h4>
<h4 id="fold"><a class="header-anchor" href="#fold">¶</a>fold</h4>
<h3 id="池化层"><a class="header-anchor" href="#池化层">¶</a>池化层</h3>
<h4 id="maxpool-1d-2d-3d"><a class="header-anchor" href="#maxpool-1d-2d-3d">¶</a>MaxPool（1d/2d/3d）</h4>
<h4 id="maxunpool-1d-2d-3d"><a class="header-anchor" href="#maxunpool-1d-2d-3d">¶</a>MaxUnpool（1d/2d/3d）</h4>
<h4 id="avgpool-1d-2d-3d"><a class="header-anchor" href="#avgpool-1d-2d-3d">¶</a>AvgPool（1d/2d/3d）</h4>
<h4 id="fractionalmaxpool2d"><a class="header-anchor" href="#fractionalmaxpool2d">¶</a>FractionalMaxPool2d</h4>
<h4 id="lppool-1d-2d"><a class="header-anchor" href="#lppool-1d-2d">¶</a>LPPool（1d/2d）</h4>
<h4 id="adaptivemaxpool-1d-2d-3d"><a class="header-anchor" href="#adaptivemaxpool-1d-2d-3d">¶</a>AdaptiveMaxPool（1d/2d/3d）</h4>
<h4 id="adaptiveavgpool-1d-2d-3d"><a class="header-anchor" href="#adaptiveavgpool-1d-2d-3d">¶</a>AdaptiveAvgPool（1d/2d/3d）</h4>
<h3 id="填充层"><a class="header-anchor" href="#填充层">¶</a>填充层</h3>
<h4 id="reflectionpad-1d-2d"><a class="header-anchor" href="#reflectionpad-1d-2d">¶</a>ReflectionPad（1d/2d）</h4>
<h4 id="replicationpad-1d-2d-3d"><a class="header-anchor" href="#replicationpad-1d-2d-3d">¶</a>ReplicationPad（1d/2d/3d）</h4>
<h4 id="zeropad2d"><a class="header-anchor" href="#zeropad2d">¶</a>ZeroPad2d</h4>
<h4 id="constantpad-1d-2d-3d"><a class="header-anchor" href="#constantpad-1d-2d-3d">¶</a>ConstantPad（1d/2d/3d）</h4>
<h3 id="激活层"><a class="header-anchor" href="#激活层">¶</a>激活层</h3>
<h4 id="relu"><a class="header-anchor" href="#relu">¶</a>ReLU</h4>
<p>LeakyReLU</p>
<p>PReLU</p>
<p>ReLU6</p>
<p>RReLU</p>
<p>SELU</p>
<p>CELU</p>
<h4 id="sigmoid"><a class="header-anchor" href="#sigmoid">¶</a>Sigmoid</h4>
<p>LogSigmoid</p>
<h4 id="tanh"><a class="header-anchor" href="#tanh">¶</a>Tanh</h4>
<p>Hardtanh</p>
<p>Tanhshrink</p>
<h4 id="softplus"><a class="header-anchor" href="#softplus">¶</a>Softplus</h4>
<h4 id="softshrink"><a class="header-anchor" href="#softshrink">¶</a>Softshrink</h4>
<h4 id="softsign"><a class="header-anchor" href="#softsign">¶</a>Softsign</h4>
<h4 id="threshold"><a class="header-anchor" href="#threshold">¶</a>Threshold</h4>
<h4 id="elu"><a class="header-anchor" href="#elu">¶</a>ELU</h4>
<h4 id="hardshrink"><a class="header-anchor" href="#hardshrink">¶</a>Hardshrink</h4>
<h3 id="末端激活层"><a class="header-anchor" href="#末端激活层">¶</a>末端激活层</h3>
<h4 id="softmin"><a class="header-anchor" href="#softmin">¶</a>Softmin</h4>
<h4 id="softmax-1d-2d"><a class="header-anchor" href="#softmax-1d-2d">¶</a>Softmax（1d/2d）</h4>
<h4 id="logsoftmax"><a class="header-anchor" href="#logsoftmax">¶</a>LogSoftmax</h4>
<h4 id="adaptivelogsoftmaxwithloss"><a class="header-anchor" href="#adaptivelogsoftmaxwithloss">¶</a>AdaptiveLogSoftmaxWithLoss</h4>
<h3 id="正则化层"><a class="header-anchor" href="#正则化层">¶</a>正则化层</h3>
<h4 id="batchnorm-1d-2d-3d"><a class="header-anchor" href="#batchnorm-1d-2d-3d">¶</a>BatchNorm（1d/2d/3d）</h4>
<h4 id="groupnorm"><a class="header-anchor" href="#groupnorm">¶</a>GroupNorm</h4>
<h4 id="instancenorm-1d-2d-3d"><a class="header-anchor" href="#instancenorm-1d-2d-3d">¶</a>InstanceNorm（1d/2d/3d）</h4>
<h4 id="layernorm"><a class="header-anchor" href="#layernorm">¶</a>LayerNorm</h4>
<h4 id="localresponsenorm"><a class="header-anchor" href="#localresponsenorm">¶</a>LocalResponseNorm</h4>
<h3 id="递归层"><a class="header-anchor" href="#递归层">¶</a>递归层</h3>
<h4 id="rnn"><a class="header-anchor" href="#rnn">¶</a>RNN</h4>
<h4 id="lstm"><a class="header-anchor" href="#lstm">¶</a>LSTM</h4>
<h4 id="gru"><a class="header-anchor" href="#gru">¶</a>GRU</h4>
<p>以及各自的cell版本</p>
<h3 id="线性层"><a class="header-anchor" href="#线性层">¶</a>线性层</h3>
<h4 id="linear"><a class="header-anchor" href="#linear">¶</a>linear</h4>
<h4 id="bilinear"><a class="header-anchor" href="#bilinear">¶</a>bilinear</h4>
<h3 id="dropout层"><a class="header-anchor" href="#dropout层">¶</a>Dropout层</h3>
<h4 id="dropout-1d-2d-3d"><a class="header-anchor" href="#dropout-1d-2d-3d">¶</a>Dropout（1d/2d/3d）</h4>
<h4 id="alphadropout"><a class="header-anchor" href="#alphadropout">¶</a>AlphaDropout</h4>
<h3 id="稀疏层-嵌入层"><a class="header-anchor" href="#稀疏层-嵌入层">¶</a>稀疏层/嵌入层</h3>
<h4 id="embedding"><a class="header-anchor" href="#embedding">¶</a>Embedding</h4>
<h4 id="embeddingbag"><a class="header-anchor" href="#embeddingbag">¶</a>EmbeddingBag</h4>
<h2 id="运算函数"><a class="header-anchor" href="#运算函数">¶</a>运算函数</h2>
<h3 id="损失函数"><a class="header-anchor" href="#损失函数">¶</a>损失函数</h3>
<p><a href="https://blog.csdn.net/shanglianlm/article/details/85019768" target="_blank" rel="noopener">https://blog.csdn.net/shanglianlm/article/details/85019768</a></p>
<p><a href="https://blog.csdn.net/jacke121/article/details/82812218" target="_blank" rel="noopener">https://blog.csdn.net/jacke121/article/details/82812218</a></p>
<h4 id="l1loss"><a class="header-anchor" href="#l1loss">¶</a>L1Loss</h4>
<h4 id="smoothl1loss"><a class="header-anchor" href="#smoothl1loss">¶</a>SmoothL1Loss</h4>
<h4 id="mseloss"><a class="header-anchor" href="#mseloss">¶</a>MSELoss</h4>
<h4 id="bceloss"><a class="header-anchor" href="#bceloss">¶</a>BCELoss</h4>
<h4 id="crossentropyloss"><a class="header-anchor" href="#crossentropyloss">¶</a>CrossEntropyLoss</h4>
<h4 id="nllloss"><a class="header-anchor" href="#nllloss">¶</a>NLLLoss</h4>
<h4 id="nllloss2d"><a class="header-anchor" href="#nllloss2d">¶</a>NLLLoss2d</h4>
<h3 id="距离计算"><a class="header-anchor" href="#距离计算">¶</a>距离计算</h3>
<h4 id="cosinesimilarity"><a class="header-anchor" href="#cosinesimilarity">¶</a>CosineSimilarity</h4>
<h4 id="pairwisedistance"><a class="header-anchor" href="#pairwisedistance">¶</a>PairwiseDistance</h4>
<h2 id="初始化"><a class="header-anchor" href="#初始化">¶</a>初始化</h2>
<h3 id="calculate-gain"><a class="header-anchor" href="#calculate-gain">¶</a>calculate_gain</h3>
<h3 id="uniform"><a class="header-anchor" href="#uniform">¶</a>uniform_</h3>
<h3 id="normal"><a class="header-anchor" href="#normal">¶</a>normal_</h3>
<h3 id="constant"><a class="header-anchor" href="#constant">¶</a>constant_</h3>
<h3 id="eye"><a class="header-anchor" href="#eye">¶</a>eye_</h3>
<h3 id="dirac"><a class="header-anchor" href="#dirac">¶</a>dirac_</h3>
<h3 id="xavier-uniform"><a class="header-anchor" href="#xavier-uniform">¶</a>xavier_uniform_</h3>
<h3 id="xavier-normal"><a class="header-anchor" href="#xavier-normal">¶</a>xavier_normal_</h3>
<h3 id="kaiming-uniform"><a class="header-anchor" href="#kaiming-uniform">¶</a>kaiming_uniform_</h3>
<h3 id="kaiming-normal"><a class="header-anchor" href="#kaiming-normal">¶</a>kaiming_normal_</h3>
<h3 id="orthogonal"><a class="header-anchor" href="#orthogonal">¶</a>orthogonal_</h3>
<h3 id="sparse"><a class="header-anchor" href="#sparse">¶</a>sparse_</h3>
<h2 id="avg-pool2d"><a class="header-anchor" href="#avg-pool2d">¶</a>avg_pool2d</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">9</span>],[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">outputs = nn.functional.avg_pool2d(inputs, <span class="number">2</span>)</span><br><span class="line">print(inputs)</span><br><span class="line">print(outputs)</span><br><span class="line"><span class="comment"># tensor([[[[1., 2., 3., 4.],</span></span><br><span class="line"><span class="comment">#           [1., 5., 3., 4.],</span></span><br><span class="line"><span class="comment">#           [1., 2., 3., 9.],</span></span><br><span class="line"><span class="comment">#           [0., 2., 3., 4.]]]])</span></span><br><span class="line"><span class="comment"># tensor([[[[2.2500, 3.5000],</span></span><br><span class="line"><span class="comment">#           [1.2500, 4.7500]]]])</span></span><br></pre></td></tr></table></figure>
<h2 id="sigmoid-v2"><a class="header-anchor" href="#sigmoid-v2">¶</a>Sigmoid</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">model = nn.Sigmoid()</span><br><span class="line">outputs = model(inputs)</span><br><span class="line">print(outputs)</span><br><span class="line"><span class="comment"># tensor([[[[0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820]]]])</span></span><br></pre></td></tr></table></figure>
<h1>优化方法</h1>
<h2 id="sgd"><a class="header-anchor" href="#sgd">¶</a>SGD</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=l2_norm)</span><br></pre></td></tr></table></figure>
<h3 id="momentum"><a class="header-anchor" href="#momentum">¶</a>momentum</h3>
<h2 id="asgd"><a class="header-anchor" href="#asgd">¶</a>ASGD</h2>
<h2 id="adagrad"><a class="header-anchor" href="#adagrad">¶</a>Adagrad</h2>
<h2 id="adadelta"><a class="header-anchor" href="#adadelta">¶</a>Adadelta</h2>
<h2 id="rmsprop"><a class="header-anchor" href="#rmsprop">¶</a>RMSprop</h2>
<h2 id="adam"><a class="header-anchor" href="#adam">¶</a>Adam</h2>
<h2 id="adamax"><a class="header-anchor" href="#adamax">¶</a>Adamax</h2>
<h2 id="sparseadam"><a class="header-anchor" href="#sparseadam">¶</a>SparseAdam</h2>
<h2 id="lbfgs"><a class="header-anchor" href="#lbfgs">¶</a>LBFGS</h2>
<h2 id="rprop"><a class="header-anchor" href="#rprop">¶</a>Rprop</h2>
<h1>内置经典网络</h1>
<h2 id="alexnet"><a class="header-anchor" href="#alexnet">¶</a>AlexNet</h2>
<h2 id="vgg"><a class="header-anchor" href="#vgg">¶</a>VGG</h2>
<h2 id="resnet"><a class="header-anchor" href="#resnet">¶</a>ResNet</h2>
<h2 id="squeezenet"><a class="header-anchor" href="#squeezenet">¶</a>SqueezeNet</h2>
<h2 id="densenet"><a class="header-anchor" href="#densenet">¶</a>DenseNet</h2>
<p>##Inception v3</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/08/机器学习-sklearn/" rel="next" title="机器学习-sklearn">
                <i class="fa fa-chevron-left"></i> 机器学习-sklearn
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/08/深度学习-其他框架/" rel="prev" title="深度学习-其他框架">
                深度学习-其他框架 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Chenxr</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">60</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#帮助文档"><span class="nav-number">1.1.</span> <span class="nav-text">¶帮助文档</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#类型及类型转换"><span class="nav-number">1.2.</span> <span class="nav-text">¶类型及类型转换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#运行模型"><span class="nav-number">1.3.</span> <span class="nav-text">¶运行模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cpu与gpu"><span class="nav-number">1.4.</span> <span class="nav-text">¶cpu与gpu</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#dataset-dataloader"><span class="nav-number">2.1.</span> <span class="nav-text">¶Dataset &amp;&amp; Dataloader</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">各种处理/转换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#view"><span class="nav-number">3.1.</span> <span class="nav-text">¶view</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#transforms"><span class="nav-number">3.2.</span> <span class="nav-text">¶transforms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#squeeze"><span class="nav-number">3.3.</span> <span class="nav-text">¶squeeze</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#unsqueeze"><span class="nav-number">3.4.</span> <span class="nav-text">¶unsqueeze</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">基本运算</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#max"><span class="nav-number">4.1.</span> <span class="nav-text">¶max</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#eq"><span class="nav-number">4.2.</span> <span class="nav-text">¶eq</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#abs"><span class="nav-number">4.3.</span> <span class="nav-text">¶abs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sin"><span class="nav-number">4.4.</span> <span class="nav-text">¶sin</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mean"><span class="nav-number">4.5.</span> <span class="nav-text">¶mean</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">5.</span> <span class="nav-text">深度学习运算</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#层"><span class="nav-number">5.1.</span> <span class="nav-text">¶层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积层"><span class="nav-number">5.1.1.</span> <span class="nav-text">¶卷积层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#conv-1d-2d-3d"><span class="nav-number">5.1.1.1.</span> <span class="nav-text">¶Conv（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#convtranspose-1d-2d-3d"><span class="nav-number">5.1.1.2.</span> <span class="nav-text">¶ConvTranspose（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#unfold"><span class="nav-number">5.1.1.3.</span> <span class="nav-text">¶Unfold</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fold"><span class="nav-number">5.1.1.4.</span> <span class="nav-text">¶fold</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#池化层"><span class="nav-number">5.1.2.</span> <span class="nav-text">¶池化层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#maxpool-1d-2d-3d"><span class="nav-number">5.1.2.1.</span> <span class="nav-text">¶MaxPool（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#maxunpool-1d-2d-3d"><span class="nav-number">5.1.2.2.</span> <span class="nav-text">¶MaxUnpool（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#avgpool-1d-2d-3d"><span class="nav-number">5.1.2.3.</span> <span class="nav-text">¶AvgPool（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fractionalmaxpool2d"><span class="nav-number">5.1.2.4.</span> <span class="nav-text">¶FractionalMaxPool2d</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#lppool-1d-2d"><span class="nav-number">5.1.2.5.</span> <span class="nav-text">¶LPPool（1d/2d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#adaptivemaxpool-1d-2d-3d"><span class="nav-number">5.1.2.6.</span> <span class="nav-text">¶AdaptiveMaxPool（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#adaptiveavgpool-1d-2d-3d"><span class="nav-number">5.1.2.7.</span> <span class="nav-text">¶AdaptiveAvgPool（1d/2d/3d）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#填充层"><span class="nav-number">5.1.3.</span> <span class="nav-text">¶填充层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#reflectionpad-1d-2d"><span class="nav-number">5.1.3.1.</span> <span class="nav-text">¶ReflectionPad（1d/2d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#replicationpad-1d-2d-3d"><span class="nav-number">5.1.3.2.</span> <span class="nav-text">¶ReplicationPad（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#zeropad2d"><span class="nav-number">5.1.3.3.</span> <span class="nav-text">¶ZeroPad2d</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#constantpad-1d-2d-3d"><span class="nav-number">5.1.3.4.</span> <span class="nav-text">¶ConstantPad（1d/2d/3d）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#激活层"><span class="nav-number">5.1.4.</span> <span class="nav-text">¶激活层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#relu"><span class="nav-number">5.1.4.1.</span> <span class="nav-text">¶ReLU</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sigmoid"><span class="nav-number">5.1.4.2.</span> <span class="nav-text">¶Sigmoid</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tanh"><span class="nav-number">5.1.4.3.</span> <span class="nav-text">¶Tanh</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#softplus"><span class="nav-number">5.1.4.4.</span> <span class="nav-text">¶Softplus</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#softshrink"><span class="nav-number">5.1.4.5.</span> <span class="nav-text">¶Softshrink</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#softsign"><span class="nav-number">5.1.4.6.</span> <span class="nav-text">¶Softsign</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#threshold"><span class="nav-number">5.1.4.7.</span> <span class="nav-text">¶Threshold</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#elu"><span class="nav-number">5.1.4.8.</span> <span class="nav-text">¶ELU</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hardshrink"><span class="nav-number">5.1.4.9.</span> <span class="nav-text">¶Hardshrink</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#末端激活层"><span class="nav-number">5.1.5.</span> <span class="nav-text">¶末端激活层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#softmin"><span class="nav-number">5.1.5.1.</span> <span class="nav-text">¶Softmin</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#softmax-1d-2d"><span class="nav-number">5.1.5.2.</span> <span class="nav-text">¶Softmax（1d/2d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#logsoftmax"><span class="nav-number">5.1.5.3.</span> <span class="nav-text">¶LogSoftmax</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#adaptivelogsoftmaxwithloss"><span class="nav-number">5.1.5.4.</span> <span class="nav-text">¶AdaptiveLogSoftmaxWithLoss</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化层"><span class="nav-number">5.1.6.</span> <span class="nav-text">¶正则化层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#batchnorm-1d-2d-3d"><span class="nav-number">5.1.6.1.</span> <span class="nav-text">¶BatchNorm（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#groupnorm"><span class="nav-number">5.1.6.2.</span> <span class="nav-text">¶GroupNorm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#instancenorm-1d-2d-3d"><span class="nav-number">5.1.6.3.</span> <span class="nav-text">¶InstanceNorm（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#layernorm"><span class="nav-number">5.1.6.4.</span> <span class="nav-text">¶LayerNorm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#localresponsenorm"><span class="nav-number">5.1.6.5.</span> <span class="nav-text">¶LocalResponseNorm</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#递归层"><span class="nav-number">5.1.7.</span> <span class="nav-text">¶递归层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#rnn"><span class="nav-number">5.1.7.1.</span> <span class="nav-text">¶RNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#lstm"><span class="nav-number">5.1.7.2.</span> <span class="nav-text">¶LSTM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gru"><span class="nav-number">5.1.7.3.</span> <span class="nav-text">¶GRU</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性层"><span class="nav-number">5.1.8.</span> <span class="nav-text">¶线性层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#linear"><span class="nav-number">5.1.8.1.</span> <span class="nav-text">¶linear</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#bilinear"><span class="nav-number">5.1.8.2.</span> <span class="nav-text">¶bilinear</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dropout层"><span class="nav-number">5.1.9.</span> <span class="nav-text">¶Dropout层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#dropout-1d-2d-3d"><span class="nav-number">5.1.9.1.</span> <span class="nav-text">¶Dropout（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#alphadropout"><span class="nav-number">5.1.9.2.</span> <span class="nav-text">¶AlphaDropout</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#稀疏层-嵌入层"><span class="nav-number">5.1.10.</span> <span class="nav-text">¶稀疏层/嵌入层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#embedding"><span class="nav-number">5.1.10.1.</span> <span class="nav-text">¶Embedding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#embeddingbag"><span class="nav-number">5.1.10.2.</span> <span class="nav-text">¶EmbeddingBag</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#运算函数"><span class="nav-number">5.2.</span> <span class="nav-text">¶运算函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数"><span class="nav-number">5.2.1.</span> <span class="nav-text">¶损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#l1loss"><span class="nav-number">5.2.1.1.</span> <span class="nav-text">¶L1Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#smoothl1loss"><span class="nav-number">5.2.1.2.</span> <span class="nav-text">¶SmoothL1Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mseloss"><span class="nav-number">5.2.1.3.</span> <span class="nav-text">¶MSELoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#bceloss"><span class="nav-number">5.2.1.4.</span> <span class="nav-text">¶BCELoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#crossentropyloss"><span class="nav-number">5.2.1.5.</span> <span class="nav-text">¶CrossEntropyLoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#nllloss"><span class="nav-number">5.2.1.6.</span> <span class="nav-text">¶NLLLoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#nllloss2d"><span class="nav-number">5.2.1.7.</span> <span class="nav-text">¶NLLLoss2d</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#距离计算"><span class="nav-number">5.2.2.</span> <span class="nav-text">¶距离计算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#cosinesimilarity"><span class="nav-number">5.2.2.1.</span> <span class="nav-text">¶CosineSimilarity</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#pairwisedistance"><span class="nav-number">5.2.2.2.</span> <span class="nav-text">¶PairwiseDistance</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#初始化"><span class="nav-number">5.3.</span> <span class="nav-text">¶初始化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#calculate-gain"><span class="nav-number">5.3.1.</span> <span class="nav-text">¶calculate_gain</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#uniform"><span class="nav-number">5.3.2.</span> <span class="nav-text">¶uniform_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#normal"><span class="nav-number">5.3.3.</span> <span class="nav-text">¶normal_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#constant"><span class="nav-number">5.3.4.</span> <span class="nav-text">¶constant_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eye"><span class="nav-number">5.3.5.</span> <span class="nav-text">¶eye_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dirac"><span class="nav-number">5.3.6.</span> <span class="nav-text">¶dirac_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#xavier-uniform"><span class="nav-number">5.3.7.</span> <span class="nav-text">¶xavier_uniform_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#xavier-normal"><span class="nav-number">5.3.8.</span> <span class="nav-text">¶xavier_normal_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kaiming-uniform"><span class="nav-number">5.3.9.</span> <span class="nav-text">¶kaiming_uniform_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kaiming-normal"><span class="nav-number">5.3.10.</span> <span class="nav-text">¶kaiming_normal_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#orthogonal"><span class="nav-number">5.3.11.</span> <span class="nav-text">¶orthogonal_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sparse"><span class="nav-number">5.3.12.</span> <span class="nav-text">¶sparse_</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#avg-pool2d"><span class="nav-number">5.4.</span> <span class="nav-text">¶avg_pool2d</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sigmoid-v2"><span class="nav-number">5.5.</span> <span class="nav-text">¶Sigmoid</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">6.</span> <span class="nav-text">优化方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#sgd"><span class="nav-number">6.1.</span> <span class="nav-text">¶SGD</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#momentum"><span class="nav-number">6.1.1.</span> <span class="nav-text">¶momentum</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#asgd"><span class="nav-number">6.2.</span> <span class="nav-text">¶ASGD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#adagrad"><span class="nav-number">6.3.</span> <span class="nav-text">¶Adagrad</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#adadelta"><span class="nav-number">6.4.</span> <span class="nav-text">¶Adadelta</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#rmsprop"><span class="nav-number">6.5.</span> <span class="nav-text">¶RMSprop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#adam"><span class="nav-number">6.6.</span> <span class="nav-text">¶Adam</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#adamax"><span class="nav-number">6.7.</span> <span class="nav-text">¶Adamax</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sparseadam"><span class="nav-number">6.8.</span> <span class="nav-text">¶SparseAdam</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lbfgs"><span class="nav-number">6.9.</span> <span class="nav-text">¶LBFGS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#rprop"><span class="nav-number">6.10.</span> <span class="nav-text">¶Rprop</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">7.</span> <span class="nav-text">内置经典网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#alexnet"><span class="nav-number">7.1.</span> <span class="nav-text">¶AlexNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#vgg"><span class="nav-number">7.2.</span> <span class="nav-text">¶VGG</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#resnet"><span class="nav-number">7.3.</span> <span class="nav-text">¶ResNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#squeezenet"><span class="nav-number">7.4.</span> <span class="nav-text">¶SqueezeNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#densenet"><span class="nav-number">7.5.</span> <span class="nav-text">¶DenseNet</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chenxr</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
