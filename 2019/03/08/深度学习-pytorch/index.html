<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="[TOC] https://ptorch.com/news/45.html 基础https://blog.csdn.net/Tan915730/article/details/78954482 函数名下划线https://blog.csdn.net/qq_27261889/article/details/86777230 函数，数据类型查询https://blog.csdn.net/zzulp/a">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习-pytorch">
<meta property="og:url" content="http://yoursite.com/2019/03/08/深度学习-pytorch/index.html">
<meta property="og:site_name" content="Chenxr&#39;s blogs">
<meta property="og:description" content="[TOC] https://ptorch.com/news/45.html 基础https://blog.csdn.net/Tan915730/article/details/78954482 函数名下划线https://blog.csdn.net/qq_27261889/article/details/86777230 函数，数据类型查询https://blog.csdn.net/zzulp/a">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-05-25T15:00:10.672Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习-pytorch">
<meta name="twitter:description" content="[TOC] https://ptorch.com/news/45.html 基础https://blog.csdn.net/Tan915730/article/details/78954482 函数名下划线https://blog.csdn.net/qq_27261889/article/details/86777230 函数，数据类型查询https://blog.csdn.net/zzulp/a">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/03/08/深度学习-pytorch/">





  <title>深度学习-pytorch | Chenxr's blogs</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chenxr's blogs</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/深度学习-pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">深度学习-pytorch</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:44:59+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>[TOC]</p>
<p><a href="https://ptorch.com/news/45.html" target="_blank" rel="noopener">https://ptorch.com/news/45.html</a></p>
<h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><p><a href="https://blog.csdn.net/Tan915730/article/details/78954482" target="_blank" rel="noopener">https://blog.csdn.net/Tan915730/article/details/78954482</a></p>
<p>函数名下划线<a href="https://blog.csdn.net/qq_27261889/article/details/86777230" target="_blank" rel="noopener">https://blog.csdn.net/qq_27261889/article/details/86777230</a></p>
<p>函数，数据类型查询<a href="https://blog.csdn.net/zzulp/article/details/80573331" target="_blank" rel="noopener">https://blog.csdn.net/zzulp/article/details/80573331</a></p>
<h2 id="帮助文档"><a href="#帮助文档" class="headerlink" title="帮助文档"></a>帮助文档</h2><p><a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">https://pytorch.org/docs/stable/index.html</a></p>
<h2 id="类型及类型转换"><a href="#类型及类型转换" class="headerlink" title="类型及类型转换"></a>类型及类型转换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">print(inputs.dtype) <span class="comment"># float32</span></span><br></pre></td></tr></table></figure>
<h2 id="运行模型"><a href="#运行模型" class="headerlink" title="运行模型"></a>运行模型</h2><p>直接运行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">model = nn.Sigmoid()</span><br><span class="line">outputs = model(inputs)</span><br><span class="line">print(outputs)</span><br><span class="line"><span class="comment"># tensor([[[[0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820]]]])</span></span><br></pre></td></tr></table></figure>
<p>通过继承nn.Module，重载__init__和forward</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sig</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__() </span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.sigmoid(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">model = sig()</span><br><span class="line">outputs = model(inputs)</span><br><span class="line">print(outputs)</span><br><span class="line"><span class="comment"># tensor([[[[0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820]]]])</span></span><br></pre></td></tr></table></figure>
<h2 id="cpu与gpu"><a href="#cpu与gpu" class="headerlink" title="cpu与gpu"></a>cpu与gpu</h2><p><a href="https://blog.csdn.net/liulina603/article/details/80180355" target="_blank" rel="noopener">https://blog.csdn.net/liulina603/article/details/80180355</a></p>
<p><a href="https://ptorch.com/news/160.html" target="_blank" rel="noopener">https://ptorch.com/news/160.html</a></p>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><h2 id="Dataset-amp-amp-Dataloader"><a href="#Dataset-amp-amp-Dataloader" class="headerlink" title="Dataset &amp;&amp; Dataloader"></a>Dataset &amp;&amp; Dataloader</h2><p>torch.utils.data.Dataset</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">trainset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#定义好 image 的路径</span></span><br><span class="line">        self.images = file_train</span><br><span class="line">        self.target = number_train</span><br><span class="line">        self.loader = loader</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        fn = self.images[index]</span><br><span class="line">        img = self.loader(fn)</span><br><span class="line">        target = self.target[index]</span><br><span class="line">        <span class="keyword">return</span> img,target</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.images)</span><br></pre></td></tr></table></figure>
<p>torch.utils.data.Dataloader</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">32</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(</span><br><span class="line">            mean=np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]),</span><br><span class="line">            std=np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])),</span><br><span class="line">    ])</span><br><span class="line"><span class="comment"># prepare dataset by ImageFolder, data should be classified by directory</span></span><br><span class="line">train_set = torchvision.datasets.ImageFolder(root = <span class="string">'./mnist/train'</span>, transform = transform)</span><br><span class="line"><span class="comment"># print(train_set[0][0])</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size = <span class="number">32</span>, shuffle = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train_loader:</span><br><span class="line">    print(i[<span class="number">0</span>].shape) <span class="comment"># torch.Size([32, 3, 32, 32])</span></span><br><span class="line">    print(i[<span class="number">1</span>].shape) <span class="comment"># torch.Size([32]) </span></span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"><span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">    print(data.shape) <span class="comment"># 同上</span></span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h1 id="各种处理-转换"><a href="#各种处理-转换" class="headerlink" title="各种处理/转换"></a>各种处理/转换</h1><h2 id="view"><a href="#view" class="headerlink" title="view"></a>view</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">img_pil =  Image.open(<span class="string">'./mnist/test/0/mnist_test_10.png'</span>)</span><br><span class="line">img_pil = img_pil.convert(<span class="string">'RGB'</span>)</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">32</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(</span><br><span class="line">        mean=np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]),</span><br><span class="line">        std=np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])),</span><br><span class="line">])</span><br><span class="line">img_pil = transform(img_pil)</span><br><span class="line">print(img_pil.shape) <span class="comment"># 3 32 32</span></span><br><span class="line">img_pil = img_pil.view(<span class="number">1</span>,img_pil.size(<span class="number">0</span>), img_pil.size(<span class="number">1</span>), img_pil.size(<span class="number">2</span>))</span><br><span class="line">print(img_pil.shape) <span class="comment"># 1 3 32 32</span></span><br></pre></td></tr></table></figure>
<h2 id="transforms"><a href="#transforms" class="headerlink" title="transforms"></a>transforms</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">32</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(</span><br><span class="line">    	mean=np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]),</span><br><span class="line">        std=np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])),</span><br><span class="line">])</span><br><span class="line">img_pil =  Image.open(<span class="string">'./mnist/test/0/mnist_test_10.png'</span>)</span><br><span class="line">img_pil = img_pil.convert(<span class="string">'RGB'</span>)</span><br><span class="line">img_pil = transform(img_pil)</span><br></pre></td></tr></table></figure>
<h2 id="squeeze"><a href="#squeeze" class="headerlink" title="squeeze"></a>squeeze</h2><h2 id="unsqueeze"><a href="#unsqueeze" class="headerlink" title="unsqueeze"></a>unsqueeze</h2><h1 id="基本运算"><a href="#基本运算" class="headerlink" title="基本运算"></a>基本运算</h1><p><a href="https://blog.csdn.net/th_num/article/details/80783037" target="_blank" rel="noopener">https://blog.csdn.net/th_num/article/details/80783037</a></p>
<h2 id="max"><a href="#max" class="headerlink" title="max"></a>max</h2><h2 id="eq"><a href="#eq" class="headerlink" title="eq"></a>eq</h2><h2 id="abs"><a href="#abs" class="headerlink" title="abs"></a>abs</h2><h2 id="sin"><a href="#sin" class="headerlink" title="sin"></a>sin</h2><h2 id="mean"><a href="#mean" class="headerlink" title="mean"></a>mean</h2><h1 id="深度学习运算"><a href="#深度学习运算" class="headerlink" title="深度学习运算"></a>深度学习运算</h1><h2 id="层"><a href="#层" class="headerlink" title="层"></a>层</h2><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><h4 id="Conv（1d-2d-3d）"><a href="#Conv（1d-2d-3d）" class="headerlink" title="Conv（1d/2d/3d）"></a>Conv（1d/2d/3d）</h4><h4 id="ConvTranspose（1d-2d-3d）"><a href="#ConvTranspose（1d-2d-3d）" class="headerlink" title="ConvTranspose（1d/2d/3d）"></a>ConvTranspose（1d/2d/3d）</h4><h4 id="Unfold"><a href="#Unfold" class="headerlink" title="Unfold"></a>Unfold</h4><h4 id="fold"><a href="#fold" class="headerlink" title="fold"></a>fold</h4><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><h4 id="MaxPool（1d-2d-3d）"><a href="#MaxPool（1d-2d-3d）" class="headerlink" title="MaxPool（1d/2d/3d）"></a>MaxPool（1d/2d/3d）</h4><h4 id="MaxUnpool（1d-2d-3d）"><a href="#MaxUnpool（1d-2d-3d）" class="headerlink" title="MaxUnpool（1d/2d/3d）"></a>MaxUnpool（1d/2d/3d）</h4><h4 id="AvgPool（1d-2d-3d）"><a href="#AvgPool（1d-2d-3d）" class="headerlink" title="AvgPool（1d/2d/3d）"></a>AvgPool（1d/2d/3d）</h4><h4 id="FractionalMaxPool2d"><a href="#FractionalMaxPool2d" class="headerlink" title="FractionalMaxPool2d"></a>FractionalMaxPool2d</h4><h4 id="LPPool（1d-2d）"><a href="#LPPool（1d-2d）" class="headerlink" title="LPPool（1d/2d）"></a>LPPool（1d/2d）</h4><h4 id="AdaptiveMaxPool（1d-2d-3d）"><a href="#AdaptiveMaxPool（1d-2d-3d）" class="headerlink" title="AdaptiveMaxPool（1d/2d/3d）"></a>AdaptiveMaxPool（1d/2d/3d）</h4><h4 id="AdaptiveAvgPool（1d-2d-3d）"><a href="#AdaptiveAvgPool（1d-2d-3d）" class="headerlink" title="AdaptiveAvgPool（1d/2d/3d）"></a>AdaptiveAvgPool（1d/2d/3d）</h4><h3 id="填充层"><a href="#填充层" class="headerlink" title="填充层"></a>填充层</h3><h4 id="ReflectionPad（1d-2d）"><a href="#ReflectionPad（1d-2d）" class="headerlink" title="ReflectionPad（1d/2d）"></a>ReflectionPad（1d/2d）</h4><h4 id="ReplicationPad（1d-2d-3d）"><a href="#ReplicationPad（1d-2d-3d）" class="headerlink" title="ReplicationPad（1d/2d/3d）"></a>ReplicationPad（1d/2d/3d）</h4><h4 id="ZeroPad2d"><a href="#ZeroPad2d" class="headerlink" title="ZeroPad2d"></a>ZeroPad2d</h4><h4 id="ConstantPad（1d-2d-3d）"><a href="#ConstantPad（1d-2d-3d）" class="headerlink" title="ConstantPad（1d/2d/3d）"></a>ConstantPad（1d/2d/3d）</h4><h3 id="激活层"><a href="#激活层" class="headerlink" title="激活层"></a>激活层</h3><h4 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h4><p>LeakyReLU</p>
<p>PReLU</p>
<p>ReLU6</p>
<p>RReLU</p>
<p>SELU</p>
<p>CELU</p>
<h4 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h4><p>LogSigmoid</p>
<h4 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h4><p>Hardtanh</p>
<p>Tanhshrink</p>
<h4 id="Softplus"><a href="#Softplus" class="headerlink" title="Softplus"></a>Softplus</h4><h4 id="Softshrink"><a href="#Softshrink" class="headerlink" title="Softshrink"></a>Softshrink</h4><h4 id="Softsign"><a href="#Softsign" class="headerlink" title="Softsign"></a>Softsign</h4><h4 id="Threshold"><a href="#Threshold" class="headerlink" title="Threshold"></a>Threshold</h4><h4 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h4><h4 id="Hardshrink"><a href="#Hardshrink" class="headerlink" title="Hardshrink"></a>Hardshrink</h4><h3 id="末端激活层"><a href="#末端激活层" class="headerlink" title="末端激活层"></a>末端激活层</h3><h4 id="Softmin"><a href="#Softmin" class="headerlink" title="Softmin"></a>Softmin</h4><h4 id="Softmax（1d-2d）"><a href="#Softmax（1d-2d）" class="headerlink" title="Softmax（1d/2d）"></a>Softmax（1d/2d）</h4><h4 id="LogSoftmax"><a href="#LogSoftmax" class="headerlink" title="LogSoftmax"></a>LogSoftmax</h4><h4 id="AdaptiveLogSoftmaxWithLoss"><a href="#AdaptiveLogSoftmaxWithLoss" class="headerlink" title="AdaptiveLogSoftmaxWithLoss"></a>AdaptiveLogSoftmaxWithLoss</h4><h3 id="正则化层"><a href="#正则化层" class="headerlink" title="正则化层"></a>正则化层</h3><h4 id="BatchNorm（1d-2d-3d）"><a href="#BatchNorm（1d-2d-3d）" class="headerlink" title="BatchNorm（1d/2d/3d）"></a>BatchNorm（1d/2d/3d）</h4><h4 id="GroupNorm"><a href="#GroupNorm" class="headerlink" title="GroupNorm"></a>GroupNorm</h4><h4 id="InstanceNorm（1d-2d-3d）"><a href="#InstanceNorm（1d-2d-3d）" class="headerlink" title="InstanceNorm（1d/2d/3d）"></a>InstanceNorm（1d/2d/3d）</h4><h4 id="LayerNorm"><a href="#LayerNorm" class="headerlink" title="LayerNorm"></a>LayerNorm</h4><h4 id="LocalResponseNorm"><a href="#LocalResponseNorm" class="headerlink" title="LocalResponseNorm"></a>LocalResponseNorm</h4><h3 id="递归层"><a href="#递归层" class="headerlink" title="递归层"></a>递归层</h3><h4 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h4><h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><h4 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h4><p>以及各自的cell版本</p>
<h3 id="线性层"><a href="#线性层" class="headerlink" title="线性层"></a>线性层</h3><h4 id="linear"><a href="#linear" class="headerlink" title="linear"></a>linear</h4><h4 id="bilinear"><a href="#bilinear" class="headerlink" title="bilinear"></a>bilinear</h4><h3 id="Dropout层"><a href="#Dropout层" class="headerlink" title="Dropout层"></a>Dropout层</h3><h4 id="Dropout（1d-2d-3d）"><a href="#Dropout（1d-2d-3d）" class="headerlink" title="Dropout（1d/2d/3d）"></a>Dropout（1d/2d/3d）</h4><h4 id="AlphaDropout"><a href="#AlphaDropout" class="headerlink" title="AlphaDropout"></a>AlphaDropout</h4><h3 id="稀疏层-嵌入层"><a href="#稀疏层-嵌入层" class="headerlink" title="稀疏层/嵌入层"></a>稀疏层/嵌入层</h3><h4 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h4><h4 id="EmbeddingBag"><a href="#EmbeddingBag" class="headerlink" title="EmbeddingBag"></a>EmbeddingBag</h4><h2 id="运算函数"><a href="#运算函数" class="headerlink" title="运算函数"></a>运算函数</h2><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p><a href="https://blog.csdn.net/shanglianlm/article/details/85019768" target="_blank" rel="noopener">https://blog.csdn.net/shanglianlm/article/details/85019768</a></p>
<p><a href="https://blog.csdn.net/jacke121/article/details/82812218" target="_blank" rel="noopener">https://blog.csdn.net/jacke121/article/details/82812218</a></p>
<h4 id="L1Loss"><a href="#L1Loss" class="headerlink" title="L1Loss"></a>L1Loss</h4><h4 id="SmoothL1Loss"><a href="#SmoothL1Loss" class="headerlink" title="SmoothL1Loss"></a>SmoothL1Loss</h4><h4 id="MSELoss"><a href="#MSELoss" class="headerlink" title="MSELoss"></a>MSELoss</h4><h4 id="BCELoss"><a href="#BCELoss" class="headerlink" title="BCELoss"></a>BCELoss</h4><h4 id="CrossEntropyLoss"><a href="#CrossEntropyLoss" class="headerlink" title="CrossEntropyLoss"></a>CrossEntropyLoss</h4><h4 id="NLLLoss"><a href="#NLLLoss" class="headerlink" title="NLLLoss"></a>NLLLoss</h4><h4 id="NLLLoss2d"><a href="#NLLLoss2d" class="headerlink" title="NLLLoss2d"></a>NLLLoss2d</h4><h3 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h3><h4 id="CosineSimilarity"><a href="#CosineSimilarity" class="headerlink" title="CosineSimilarity"></a>CosineSimilarity</h4><h4 id="PairwiseDistance"><a href="#PairwiseDistance" class="headerlink" title="PairwiseDistance"></a>PairwiseDistance</h4><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><h3 id="calculate-gain"><a href="#calculate-gain" class="headerlink" title="calculate_gain"></a>calculate_gain</h3><h3 id="uniform"><a href="#uniform" class="headerlink" title="uniform_"></a>uniform_</h3><h3 id="normal"><a href="#normal" class="headerlink" title="normal_"></a>normal_</h3><h3 id="constant"><a href="#constant" class="headerlink" title="constant_"></a>constant_</h3><h3 id="eye"><a href="#eye" class="headerlink" title="eye_"></a>eye_</h3><h3 id="dirac"><a href="#dirac" class="headerlink" title="dirac_"></a>dirac_</h3><h3 id="xavieruniform"><a href="#xavieruniform" class="headerlink" title="xavieruniform"></a>xavier<em>uniform</em></h3><h3 id="xaviernormal"><a href="#xaviernormal" class="headerlink" title="xaviernormal"></a>xavier<em>normal</em></h3><h3 id="kaiminguniform"><a href="#kaiminguniform" class="headerlink" title="kaiminguniform"></a>kaiming<em>uniform</em></h3><h3 id="kaimingnormal"><a href="#kaimingnormal" class="headerlink" title="kaimingnormal"></a>kaiming<em>normal</em></h3><h3 id="orthogonal"><a href="#orthogonal" class="headerlink" title="orthogonal_"></a>orthogonal_</h3><h3 id="sparse"><a href="#sparse" class="headerlink" title="sparse_"></a>sparse_</h3><h2 id="avg-pool2d"><a href="#avg-pool2d" class="headerlink" title="avg_pool2d"></a>avg_pool2d</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">9</span>],[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">outputs = nn.functional.avg_pool2d(inputs, <span class="number">2</span>)</span><br><span class="line">print(inputs)</span><br><span class="line">print(outputs)</span><br><span class="line"><span class="comment"># tensor([[[[1., 2., 3., 4.],</span></span><br><span class="line"><span class="comment">#           [1., 5., 3., 4.],</span></span><br><span class="line"><span class="comment">#           [1., 2., 3., 9.],</span></span><br><span class="line"><span class="comment">#           [0., 2., 3., 4.]]]])</span></span><br><span class="line"><span class="comment"># tensor([[[[2.2500, 3.5000],</span></span><br><span class="line"><span class="comment">#           [1.2500, 4.7500]]]])</span></span><br></pre></td></tr></table></figure>
<h2 id="Sigmoid-1"><a href="#Sigmoid-1" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">inputs = [[[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]]]</span><br><span class="line">inputs = torch.tensor(inputs, dtype=torch.float32) <span class="comment"># 类型转换</span></span><br><span class="line">model = nn.Sigmoid()</span><br><span class="line">outputs = model(inputs)</span><br><span class="line">print(outputs)</span><br><span class="line"><span class="comment"># tensor([[[[0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820],</span></span><br><span class="line"><span class="comment">#           [0.7311, 0.8808, 0.9526, 0.9820]]]])</span></span><br></pre></td></tr></table></figure>
<h1 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h1><h2 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=l2_norm)</span><br></pre></td></tr></table></figure>
<h3 id="momentum"><a href="#momentum" class="headerlink" title="momentum"></a>momentum</h3><h2 id="ASGD"><a href="#ASGD" class="headerlink" title="ASGD"></a>ASGD</h2><h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><h2 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h2><h2 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h2><h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><h2 id="Adamax"><a href="#Adamax" class="headerlink" title="Adamax"></a>Adamax</h2><h2 id="SparseAdam"><a href="#SparseAdam" class="headerlink" title="SparseAdam"></a>SparseAdam</h2><h2 id="LBFGS"><a href="#LBFGS" class="headerlink" title="LBFGS"></a>LBFGS</h2><h2 id="Rprop"><a href="#Rprop" class="headerlink" title="Rprop"></a>Rprop</h2><h1 id="内置经典网络"><a href="#内置经典网络" class="headerlink" title="内置经典网络"></a>内置经典网络</h1><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><h2 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h2><h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><h2 id="SqueezeNet"><a href="#SqueezeNet" class="headerlink" title="SqueezeNet"></a>SqueezeNet</h2><h2 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h2><h2 id="Inception-v3"><a href="#Inception-v3" class="headerlink" title="Inception v3"></a>Inception v3</h2>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/08/深度学习-其他框架/" rel="next" title="深度学习-其他框架">
                <i class="fa fa-chevron-left"></i> 深度学习-其他框架
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/08/机器学习-决策树/" rel="prev" title="机器学习-决策树">
                机器学习-决策树 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Chenxr</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">60</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#基础"><span class="nav-number">1.</span> <span class="nav-text">基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#帮助文档"><span class="nav-number">1.1.</span> <span class="nav-text">帮助文档</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#类型及类型转换"><span class="nav-number">1.2.</span> <span class="nav-text">类型及类型转换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#运行模型"><span class="nav-number">1.3.</span> <span class="nav-text">运行模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cpu与gpu"><span class="nav-number">1.4.</span> <span class="nav-text">cpu与gpu</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据集"><span class="nav-number">2.</span> <span class="nav-text">数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Dataset-amp-amp-Dataloader"><span class="nav-number">2.1.</span> <span class="nav-text">Dataset &amp;&amp; Dataloader</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#各种处理-转换"><span class="nav-number">3.</span> <span class="nav-text">各种处理/转换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#view"><span class="nav-number">3.1.</span> <span class="nav-text">view</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#transforms"><span class="nav-number">3.2.</span> <span class="nav-text">transforms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#squeeze"><span class="nav-number">3.3.</span> <span class="nav-text">squeeze</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#unsqueeze"><span class="nav-number">3.4.</span> <span class="nav-text">unsqueeze</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基本运算"><span class="nav-number">4.</span> <span class="nav-text">基本运算</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#max"><span class="nav-number">4.1.</span> <span class="nav-text">max</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#eq"><span class="nav-number">4.2.</span> <span class="nav-text">eq</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#abs"><span class="nav-number">4.3.</span> <span class="nav-text">abs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sin"><span class="nav-number">4.4.</span> <span class="nav-text">sin</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mean"><span class="nav-number">4.5.</span> <span class="nav-text">mean</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度学习运算"><span class="nav-number">5.</span> <span class="nav-text">深度学习运算</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#层"><span class="nav-number">5.1.</span> <span class="nav-text">层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积层"><span class="nav-number">5.1.1.</span> <span class="nav-text">卷积层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Conv（1d-2d-3d）"><span class="nav-number">5.1.1.1.</span> <span class="nav-text">Conv（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ConvTranspose（1d-2d-3d）"><span class="nav-number">5.1.1.2.</span> <span class="nav-text">ConvTranspose（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Unfold"><span class="nav-number">5.1.1.3.</span> <span class="nav-text">Unfold</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fold"><span class="nav-number">5.1.1.4.</span> <span class="nav-text">fold</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#池化层"><span class="nav-number">5.1.2.</span> <span class="nav-text">池化层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MaxPool（1d-2d-3d）"><span class="nav-number">5.1.2.1.</span> <span class="nav-text">MaxPool（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MaxUnpool（1d-2d-3d）"><span class="nav-number">5.1.2.2.</span> <span class="nav-text">MaxUnpool（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AvgPool（1d-2d-3d）"><span class="nav-number">5.1.2.3.</span> <span class="nav-text">AvgPool（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FractionalMaxPool2d"><span class="nav-number">5.1.2.4.</span> <span class="nav-text">FractionalMaxPool2d</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LPPool（1d-2d）"><span class="nav-number">5.1.2.5.</span> <span class="nav-text">LPPool（1d/2d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AdaptiveMaxPool（1d-2d-3d）"><span class="nav-number">5.1.2.6.</span> <span class="nav-text">AdaptiveMaxPool（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AdaptiveAvgPool（1d-2d-3d）"><span class="nav-number">5.1.2.7.</span> <span class="nav-text">AdaptiveAvgPool（1d/2d/3d）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#填充层"><span class="nav-number">5.1.3.</span> <span class="nav-text">填充层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ReflectionPad（1d-2d）"><span class="nav-number">5.1.3.1.</span> <span class="nav-text">ReflectionPad（1d/2d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReplicationPad（1d-2d-3d）"><span class="nav-number">5.1.3.2.</span> <span class="nav-text">ReplicationPad（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ZeroPad2d"><span class="nav-number">5.1.3.3.</span> <span class="nav-text">ZeroPad2d</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ConstantPad（1d-2d-3d）"><span class="nav-number">5.1.3.4.</span> <span class="nav-text">ConstantPad（1d/2d/3d）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#激活层"><span class="nav-number">5.1.4.</span> <span class="nav-text">激活层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ReLU"><span class="nav-number">5.1.4.1.</span> <span class="nav-text">ReLU</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sigmoid"><span class="nav-number">5.1.4.2.</span> <span class="nav-text">Sigmoid</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tanh"><span class="nav-number">5.1.4.3.</span> <span class="nav-text">Tanh</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Softplus"><span class="nav-number">5.1.4.4.</span> <span class="nav-text">Softplus</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Softshrink"><span class="nav-number">5.1.4.5.</span> <span class="nav-text">Softshrink</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Softsign"><span class="nav-number">5.1.4.6.</span> <span class="nav-text">Softsign</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Threshold"><span class="nav-number">5.1.4.7.</span> <span class="nav-text">Threshold</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ELU"><span class="nav-number">5.1.4.8.</span> <span class="nav-text">ELU</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hardshrink"><span class="nav-number">5.1.4.9.</span> <span class="nav-text">Hardshrink</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#末端激活层"><span class="nav-number">5.1.5.</span> <span class="nav-text">末端激活层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Softmin"><span class="nav-number">5.1.5.1.</span> <span class="nav-text">Softmin</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Softmax（1d-2d）"><span class="nav-number">5.1.5.2.</span> <span class="nav-text">Softmax（1d/2d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LogSoftmax"><span class="nav-number">5.1.5.3.</span> <span class="nav-text">LogSoftmax</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AdaptiveLogSoftmaxWithLoss"><span class="nav-number">5.1.5.4.</span> <span class="nav-text">AdaptiveLogSoftmaxWithLoss</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化层"><span class="nav-number">5.1.6.</span> <span class="nav-text">正则化层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#BatchNorm（1d-2d-3d）"><span class="nav-number">5.1.6.1.</span> <span class="nav-text">BatchNorm（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#GroupNorm"><span class="nav-number">5.1.6.2.</span> <span class="nav-text">GroupNorm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#InstanceNorm（1d-2d-3d）"><span class="nav-number">5.1.6.3.</span> <span class="nav-text">InstanceNorm（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LayerNorm"><span class="nav-number">5.1.6.4.</span> <span class="nav-text">LayerNorm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LocalResponseNorm"><span class="nav-number">5.1.6.5.</span> <span class="nav-text">LocalResponseNorm</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#递归层"><span class="nav-number">5.1.7.</span> <span class="nav-text">递归层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RNN"><span class="nav-number">5.1.7.1.</span> <span class="nav-text">RNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LSTM"><span class="nav-number">5.1.7.2.</span> <span class="nav-text">LSTM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#GRU"><span class="nav-number">5.1.7.3.</span> <span class="nav-text">GRU</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性层"><span class="nav-number">5.1.8.</span> <span class="nav-text">线性层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#linear"><span class="nav-number">5.1.8.1.</span> <span class="nav-text">linear</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#bilinear"><span class="nav-number">5.1.8.2.</span> <span class="nav-text">bilinear</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dropout层"><span class="nav-number">5.1.9.</span> <span class="nav-text">Dropout层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Dropout（1d-2d-3d）"><span class="nav-number">5.1.9.1.</span> <span class="nav-text">Dropout（1d/2d/3d）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AlphaDropout"><span class="nav-number">5.1.9.2.</span> <span class="nav-text">AlphaDropout</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#稀疏层-嵌入层"><span class="nav-number">5.1.10.</span> <span class="nav-text">稀疏层/嵌入层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Embedding"><span class="nav-number">5.1.10.1.</span> <span class="nav-text">Embedding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#EmbeddingBag"><span class="nav-number">5.1.10.2.</span> <span class="nav-text">EmbeddingBag</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#运算函数"><span class="nav-number">5.2.</span> <span class="nav-text">运算函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数"><span class="nav-number">5.2.1.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#L1Loss"><span class="nav-number">5.2.1.1.</span> <span class="nav-text">L1Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SmoothL1Loss"><span class="nav-number">5.2.1.2.</span> <span class="nav-text">SmoothL1Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MSELoss"><span class="nav-number">5.2.1.3.</span> <span class="nav-text">MSELoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#BCELoss"><span class="nav-number">5.2.1.4.</span> <span class="nav-text">BCELoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CrossEntropyLoss"><span class="nav-number">5.2.1.5.</span> <span class="nav-text">CrossEntropyLoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NLLLoss"><span class="nav-number">5.2.1.6.</span> <span class="nav-text">NLLLoss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NLLLoss2d"><span class="nav-number">5.2.1.7.</span> <span class="nav-text">NLLLoss2d</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#距离计算"><span class="nav-number">5.2.2.</span> <span class="nav-text">距离计算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CosineSimilarity"><span class="nav-number">5.2.2.1.</span> <span class="nav-text">CosineSimilarity</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PairwiseDistance"><span class="nav-number">5.2.2.2.</span> <span class="nav-text">PairwiseDistance</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#初始化"><span class="nav-number">5.3.</span> <span class="nav-text">初始化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#calculate-gain"><span class="nav-number">5.3.1.</span> <span class="nav-text">calculate_gain</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#uniform"><span class="nav-number">5.3.2.</span> <span class="nav-text">uniform_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#normal"><span class="nav-number">5.3.3.</span> <span class="nav-text">normal_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#constant"><span class="nav-number">5.3.4.</span> <span class="nav-text">constant_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eye"><span class="nav-number">5.3.5.</span> <span class="nav-text">eye_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dirac"><span class="nav-number">5.3.6.</span> <span class="nav-text">dirac_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#xavieruniform"><span class="nav-number">5.3.7.</span> <span class="nav-text">xavieruniform</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#xaviernormal"><span class="nav-number">5.3.8.</span> <span class="nav-text">xaviernormal</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kaiminguniform"><span class="nav-number">5.3.9.</span> <span class="nav-text">kaiminguniform</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kaimingnormal"><span class="nav-number">5.3.10.</span> <span class="nav-text">kaimingnormal</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#orthogonal"><span class="nav-number">5.3.11.</span> <span class="nav-text">orthogonal_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sparse"><span class="nav-number">5.3.12.</span> <span class="nav-text">sparse_</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#avg-pool2d"><span class="nav-number">5.4.</span> <span class="nav-text">avg_pool2d</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sigmoid-1"><span class="nav-number">5.5.</span> <span class="nav-text">Sigmoid</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#优化方法"><span class="nav-number">6.</span> <span class="nav-text">优化方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#SGD"><span class="nav-number">6.1.</span> <span class="nav-text">SGD</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#momentum"><span class="nav-number">6.1.1.</span> <span class="nav-text">momentum</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ASGD"><span class="nav-number">6.2.</span> <span class="nav-text">ASGD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adagrad"><span class="nav-number">6.3.</span> <span class="nav-text">Adagrad</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adadelta"><span class="nav-number">6.4.</span> <span class="nav-text">Adadelta</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RMSprop"><span class="nav-number">6.5.</span> <span class="nav-text">RMSprop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adam"><span class="nav-number">6.6.</span> <span class="nav-text">Adam</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adamax"><span class="nav-number">6.7.</span> <span class="nav-text">Adamax</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SparseAdam"><span class="nav-number">6.8.</span> <span class="nav-text">SparseAdam</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LBFGS"><span class="nav-number">6.9.</span> <span class="nav-text">LBFGS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Rprop"><span class="nav-number">6.10.</span> <span class="nav-text">Rprop</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#内置经典网络"><span class="nav-number">7.</span> <span class="nav-text">内置经典网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#AlexNet"><span class="nav-number">7.1.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VGG"><span class="nav-number">7.2.</span> <span class="nav-text">VGG</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNet"><span class="nav-number">7.3.</span> <span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SqueezeNet"><span class="nav-number">7.4.</span> <span class="nav-text">SqueezeNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DenseNet"><span class="nav-number">7.5.</span> <span class="nav-text">DenseNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Inception-v3"><span class="nav-number">7.6.</span> <span class="nav-text">Inception v3</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chenxr</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
