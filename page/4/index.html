<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Chenxr&#39;s blogs">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="Chenxr&#39;s blogs">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chenxr&#39;s blogs">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/">





  <title>Chenxr's blogs</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chenxr's blogs</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/深度学习-基础篇/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/深度学习-基础篇/" itemprop="url">深度学习-基础篇</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:42:19+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1>介绍</h1>
<p>人工神经网络(Artificial Neural Networks, ANN)是一种种应用类似于大脑神经突触联接的结构进行信息处理的数学模型。在这种模型中，大量的节点(或称”神经元”，或”单元&quot;)之间相互联接构成网络，即&quot;神经网络”，以达到处理信息的目的。神经网络通常需要进行训练，训练的过程就是网络进行学习的过程。训练改变了网络节点的连接权的值使其具有分类的功能，经过训练的网络就可用于对象的识别。</p>
<p>目前，神经网络已有上百种不同的模型，常见的有BP网络、径向基RBF网络、Hopfield网络、 随机神经网络(Boltzmann机) 、竞争神经网络(Hamming网络，自组织映射网络)等。但是当前的神经网络仍普遍存在计算量大、收敛速度慢、训练时间长和不可解释等缺点。</p>
<h1>基础</h1>
<p>深度学习也叫多层感知机（MLP，Multilayer Perceptron）</p>
<p><img src="/2019/03/08/深度学习-基础篇/1.png" alt="1"></p>
<p><img src="/2019/03/08/深度学习-基础篇/2.png" alt="2"></p>
<p><img src="/2019/03/08/深度学习-基础篇/3.png" alt="3"></p>
<p><img src="/2019/03/08/深度学习-基础篇/4.png" alt="4"></p>
<p><img src="/2019/03/08/深度学习-基础篇/5.png" alt="5"></p>
<p><img src="/2019/03/08/深度学习-基础篇/6.png" alt="6"></p>
<p><img src="/2019/03/08/深度学习-基础篇/8.png" alt="8"></p>
<p><img src="/2019/03/08/深度学习-基础篇/9.png" alt="9"></p>
<h1>激活函数</h1>
<p><img src="/2019/03/08/深度学习-基础篇/11.png" alt="11"></p>
<p><img src="/2019/03/08/深度学习-基础篇/12.png" alt="12"></p>
<p><img src="/2019/03/08/深度学习-基础篇/13.png" alt="13"></p>
<h1>损失函数-交叉熵</h1>
<p><img src="/2019/03/08/深度学习-基础篇/14.png" alt="14"></p>
<p><img src="/2019/03/08/深度学习-基础篇/15.png" alt="15"></p>
<p>其他：</p>
<p>均方差损失，负对数似然损失，带泊松分布的负对数似然损失</p>
<p><a href="https://blog.csdn.net/u010976453/article/details/78488279" target="_blank" rel="noopener">https://blog.csdn.net/u010976453/article/details/78488279</a></p>
<p><a href="https://www.cnblogs.com/shixiangwan/p/7953591.html" target="_blank" rel="noopener">https://www.cnblogs.com/shixiangwan/p/7953591.html</a></p>
<p>Triplet Loss</p>
<h1>softmax</h1>
<p><img src="/2019/03/08/深度学习-基础篇/10.png" alt="10"></p>
<p>LogSoftmax</p>
<h1>梯度下降</h1>
<p><img src="/2019/03/08/深度学习-基础篇/16.png" alt="16"></p>
<p><img src="/2019/03/08/深度学习-基础篇/17.png" alt="17"></p>
<p><img src="/2019/03/08/深度学习-基础篇/18.png" alt="18"></p>
<h1>后向传播</h1>
<p><img src="/2019/03/08/深度学习-基础篇/19.png" alt="19"></p>
<p><img src="/2019/03/08/深度学习-基础篇/20.png" alt="20"></p>
<p><img src="/2019/03/08/深度学习-基础篇/21.png" alt="21"></p>
<p><img src="/2019/03/08/深度学习-基础篇/22.png" alt="22"></p>
<p><img src="/2019/03/08/深度学习-基础篇/23.png" alt="23"></p>
<p><img src="/2019/03/08/深度学习-基础篇/24.png" alt="24"></p>
<p><img src="/2019/03/08/深度学习-基础篇/25.png" alt="25"></p>
<p><img src="/2019/03/08/深度学习-基础篇/26.png" alt="26"></p>
<p><img src="/2019/03/08/深度学习-基础篇/27.png" alt="27"></p>
<p><img src="/2019/03/08/深度学习-基础篇/28.png" alt="28"></p>
<p>后向传播算法一般形式（草稿纸6）</p>
<h1>优化策略</h1>
<p><img src="/2019/03/08/深度学习-基础篇/29.png" alt="29"></p>
<h2 id="batch-size"><a class="header-anchor" href="#batch-size">¶</a>batch_size</h2>
<p><img src="/2019/03/08/深度学习-基础篇/30.png" alt="30"></p>
<p><img src="/2019/03/08/深度学习-基础篇/31.png" alt="31"></p>
<p><img src="/2019/03/08/深度学习-基础篇/32.png" alt="32"></p>
<p><img src="/2019/03/08/深度学习-基础篇/33.png" alt="33"></p>
<p>Batch 的选择，首先决定的是下降的方向。如果数据集比较小，完全可以采用全数据集 （ Full Batch Learning ）的形式，这样做至少有 2 个好处：其一，由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。其二，由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。 Full Batch Learning 可以使用 Rprop 只基于梯度符号并且针对性单独更新各权值。</p>
<p>对于更大的数据集，以上 2 个好处又变成了 2 个坏处：其一，随着数据集的海量增长和内存限制，一次性载入所有的数据进来变得越来越不可行。其二，以 Rprop 的方式迭代，会由于各个 Batch 之间的采样差异性，各次梯度修正值相互抵消，无法修正。这才有了后来 RMSProp 的妥协方案。</p>
<p><strong>在合理范围内，增大 Batch_Size 有何好处？</strong></p>
<ul>
<li>内存利用率提高了，大矩阵乘法的并行化效率提高。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。</li>
<li>在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。</li>
</ul>
<p><strong>盲目增大 Batch_Size 有何坏处？</strong></p>
<ul>
<li>内存利用率提高了，但是内存容量可能撑不住了。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。</li>
<li>Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化</li>
</ul>
<p>关于batch_size的一个测试，运行结果与上文分析相印证：</p>
<ul>
<li>Batch_Size 太小，算法在 200 epoches 内不收敛。</li>
<li>随着 Batch_Size 增大，处理相同数据量的速度越快。</li>
<li>随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。</li>
<li>由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到时间上的最优。</li>
<li>由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛精度上的最优</li>
</ul>
<p><strong>小批量训练网络的优点：</strong></p>
<ul>
<li>相对海量的的数据集和内存容量，小批量处理需要更少的内存就可以训练网络。</li>
<li>通常小批量训练网络速度更快，例如我们将一个大样本分成11小样本(每个样本100个数据)，采用小批量训练网络时，每次传播后更新权重，就传播了11批，在每批次后我们均更新了网络的（权重）参数；如果在传播过程中使用了一个大样本，我们只会对训练网络的权重参数进行1次更新。</li>
<li>全数据集确定的方向能够更好地代表样本总体，从而能够更准确地朝着极值所在的方向；但是不同权值的梯度值差别较大，因此选取一个全局的学习率很困难。</li>
</ul>
<p><strong>小批量训练网络的缺点：</strong></p>
<ul>
<li>批次越小，梯度的估值就越不准确，在下图中，我们可以看到，与完整批次渐变（蓝色）方向相比，小批量渐变（绿色）的方向波动更大。</li>
<li>极端特例batch_size = 1，也成为在线学习（online learning）；线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是椭圆，对于多层神经元、非线性网络，在局部依然近似是抛物面，使用online learning，每次修正方向以各自样本的梯度方向修正，这就造成了波动较大，难以达到收敛效果。</li>
</ul>
<p><strong>如何选择合适的batch_size值：</strong></p>
<ul>
<li>采用批梯度下降法mini batch learning时，如果数据集足够充分，用一半（甚至少的多）的数据训练算出来的梯度与全数据集训练full batch learning出来的梯度几乎一样。</li>
<li>在合理的范围内，增大batch_size可以提高内存利用率，大矩阵乘法的并行化效率提高；跑完一次epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快；在适当的范围内，batch_size越大，其确定的下降方向越准，引起训练波动越小。<strong>注意，当batch_size增大到一定程度，其确定的下降方向基本不会变化</strong>。</li>
<li>batch_size值增大到超过合理范围时，和全数据训练full batch learning就会表现出相近的症候；内存容量占有率增加，跑完一次epoch（全数据集）所需的迭代次数减少，达到相同的精度所耗损的时间增加，从而对参数的修正也就显得更加缓慢。</li>
</ul>
<h2 id="momentum-nad"><a class="header-anchor" href="#momentum-nad">¶</a>momentum/NAD</h2>
<p><img src="/2019/03/08/深度学习-基础篇/34.png" alt="34"></p>
<p>1.动量方法主要是为了解决Hessian矩阵病态条件问题（直观上讲就是梯度高度敏感于参数空间的某些方向）的。</p>
<p>2.加速学习</p>
<p>3.一般将参数设为0.5,0.9，或者0.99，分别表示最大速度2倍，10倍，100倍于SGD的算法。</p>
<p>4.通过速度v，来积累了之间梯度指数级衰减的平均，并且继续延该方向移动：</p>
<p>如图所示，红色为SGD+Momentum。黑色为SGD。可以看到黑色为典型Hessian矩阵病态的情况，相当于大幅度的徘徊着向最低点前进。</p>
<p>而由于动量积攒了历史的梯度，如点P前一刻的梯度与当前的梯度方向几乎相反。因此原本在P点原本要大幅徘徊的梯度，主要受到前一时刻的影响，而导致在当前时刻的梯度幅度减小。</p>
<p>直观上讲就是，要是当前时刻的梯度与历史时刻梯度方向相似，这种趋势在当前时刻则会加强；要是不同，则当前时刻的梯度方向减弱。</p>
<p><img src="/2019/03/08/深度学习-基础篇/35.png" alt="35"></p>
<p><img src="/2019/03/08/深度学习-基础篇/36.png" alt="36"></p>
<p><img src="/2019/03/08/深度学习-基础篇/37.png" alt="37"></p>
<p>1.Nesterov是Momentum的变种。</p>
<p>2.与Momentum唯一区别就是，计算梯度的不同，Nesterov先用当前的速度v更新一遍参数，在用更新的临时参数计算梯度。</p>
<p>3.相当于添加了矫正因子的Momentum。</p>
<p>4.在GD下，Nesterov将误差收敛从O（1/k），改进到O(1/k^2)</p>
<p>5.然而在SGD下，Nesterov并没有任何改进</p>
<p>举个通俗的例子就是，你在下坡时，如果在下坡快到底，但又未到底时，动量梯度下降会让你冲到坡的对面去。Nesterov梯度下降会预知你的下一步将会时到坡的对面去，所以会提示你提前刹车，避免过度冲到坡的对面去。这包含了一种提前计算下一步的梯度，来指导当前梯度的想法</p>
<h2 id="adagrad-rprop-rmsprop"><a class="header-anchor" href="#adagrad-rprop-rmsprop">¶</a>Adagrad/Rprop/RMSprop</h2>
<p><img src="/2019/03/08/深度学习-基础篇/38.png" alt="38"></p>
<p>1.简单来讲，设置全局学习率之后，每次通过，全局学习率逐参数的除以历史梯度平方和的平方根，使得每个参数的学习率不同</p>
<p>2.效果是：在参数空间更为平缓的方向，会取得更大的进步（因为平缓，所以历史梯度平方和较小，对应学习下降的幅度较小）</p>
<p>3.缺点是,使得学习率过早，过量的减少</p>
<p>4.在某些模型上效果不错。</p>
<p><img src="/2019/03/08/深度学习-基础篇/39.png" alt="39"></p>
<p><strong>RProp算法</strong></p>
<ol>
<li>首先为各权重变化赋一个初始值，设定权重变化加速因子与减速因子。</li>
<li>在网络前馈迭代中当连续误差梯度符号不变时，采用加速策略，加快训练速度；当连续误差梯度符号变化时，采用减速策略，以期稳定收敛。</li>
<li>网络结合当前误差梯度符号与变化步长实现BP，同时，为了避免网络学习发生振荡或下溢，算法要求设定权重变化的上下限。</li>
</ol>
<p><strong>不同权值参数的梯度的数量级可能相差很大，因此很难找到一个全局的学习步长。</strong></p>
<p><strong>靠参数梯度的符号，动态的调节学习步长</strong></p>
<p><strong>适用于full-batch learning，不适用于mini-batch learning</strong></p>
<p>缺点：不能应用于mini-batch learning中。</p>
<p>原因：</p>
<p>假设有一个在线学习系统，batch==1，初始的学习步长较小，在其上应用prop算法。这里有十组训练数据，前九组都使得梯度符号与之前的梯度符号相同，那么学习步长就会增加九次；而第十次得来的梯度符号与之前的相反，那么学习步长就会减小一次。这样一个过程下来，学习步长会增长很多（增大了9次学习步长，只减小了一次学习步长），如果系统的训练数据集非常之大，那学习步长可能频繁的来回波动，这样肯定是不利于学习的</p>
<p><img src="/2019/03/08/深度学习-基础篇/40.png" alt="40"></p>
<p>1.<a href="http://blog.csdn.net/bvl10101111/article/details/72616097" target="_blank" rel="noopener">AdaGrad</a>算法的改进。鉴于神经网络都是非凸条件下的，RMSProp在非凸条件下结果更好，改变梯度累积为指数衰减的移动平均以丢弃遥远的过去历史。</p>
<p>2.经验上，RMSProp被证明有效且实用的深度学习网络优化算法。</p>
<h2 id="adam"><a class="header-anchor" href="#adam">¶</a>Adam</h2>
<p><img src="/2019/03/08/深度学习-基础篇/41.png" alt="41"></p>
<p>1.Adam算法可以看做是修正后的<a href="http://blog.csdn.net/bvl10101111/article/details/72615621" target="_blank" rel="noopener">Momentum</a>+<a href="http://blog.csdn.net/BVL10101111/article/details/72616378" target="_blank" rel="noopener">RMSProp</a>算法</p>
<p>2.动量直接并入梯度一阶矩估计中（指数加权）</p>
<p>3.Adam通常被认为对超参数的选择相当鲁棒</p>
<p>4.学习率建议为0.001</p>
<p><img src="/2019/03/08/深度学习-基础篇/42.png" alt="42"></p>
<p>Adadelta，MBGD</p>
<p><a href="https://blog.csdn.net/u010089444/article/details/76725843" target="_blank" rel="noopener">https://blog.csdn.net/u010089444/article/details/76725843</a></p>
<p><a href="https://www.cnblogs.com/guoyaohua/p/8542554.html" target="_blank" rel="noopener">https://www.cnblogs.com/guoyaohua/p/8542554.html</a></p>
<h2 id="学习率"><a class="header-anchor" href="#学习率">¶</a>学习率</h2>
<p><img src="/2019/03/08/深度学习-基础篇/43.png" alt="43"></p>
<p><a href="https://baijiahao.baidu.com/s?id=1591271039698173396&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">https://baijiahao.baidu.com/s?id=1591271039698173396&amp;wfr=spider&amp;for=pc</a></p>
<h2 id="超参数选择"><a class="header-anchor" href="#超参数选择">¶</a>超参数选择</h2>
<p><img src="/2019/03/08/深度学习-基础篇/44.png" alt="44"></p>
<p><img src="/2019/03/08/深度学习-基础篇/45.png" alt="45"></p>
<p><img src="/2019/03/08/深度学习-基础篇/46.png" alt="46"></p>
<p><img src="/2019/03/08/深度学习-基础篇/47.png" alt="47"></p>
<p><img src="/2019/03/08/深度学习-基础篇/48.png" alt="48"></p>
<p><img src="/2019/03/08/深度学习-基础篇/49.png" alt="49"></p>
<h2 id="batch-normalization-group-normalization"><a class="header-anchor" href="#batch-normalization-group-normalization">¶</a>Batch Normalization &amp; Group Normalization</h2>
<h1>学习中的问题及解决方法</h1>
<h2 id="梯度消失-爆炸"><a class="header-anchor" href="#梯度消失-爆炸">¶</a>梯度消失/爆炸</h2>
<p><img src="/2019/03/08/深度学习-基础篇/51.png" alt="51"></p>
<p><img src="/2019/03/08/深度学习-基础篇/52.png" alt="52"></p>
<p><img src="/2019/03/08/深度学习-基础篇/53.png" alt="53"></p>
<p><img src="/2019/03/08/深度学习-基础篇/54.png" alt="54"></p>
<p><img src="/2019/03/08/深度学习-基础篇/55.png" alt="55"></p>
<p><img src="/2019/03/08/深度学习-基础篇/56.png" alt="56"></p>
<p><img src="/2019/03/08/深度学习-基础篇/57.png" alt="57"></p>
<p><img src="/2019/03/08/深度学习-基础篇/58.png" alt="58"></p>
<p>weight_decay</p>
<h2 id="小批数据问题"><a class="header-anchor" href="#小批数据问题">¶</a>小批数据问题</h2>
<p><img src="/2019/03/08/深度学习-基础篇/59.png" alt="59"></p>
<p><img src="/2019/03/08/深度学习-基础篇/60.png" alt="60"></p>
<p><img src="/2019/03/08/深度学习-基础篇/61.png" alt="61"></p>
<p><img src="/2019/03/08/深度学习-基础篇/62.png" alt="62"></p>
<h2 id="过拟合问题"><a class="header-anchor" href="#过拟合问题">¶</a>过拟合问题</h2>
<p><img src="/2019/03/08/深度学习-基础篇/63.png" alt="63"></p>
<p><img src="/2019/03/08/深度学习-基础篇/64.png" alt="64"></p>
<p><img src="/2019/03/08/深度学习-基础篇/65.png" alt="65"></p>
<p><img src="/2019/03/08/深度学习-基础篇/66.png" alt="66"></p>
<p>dropout</p>
<p><a href="http://blog.csdn.net/hjimce/article/details/50413257" target="_blank" rel="noopener">http://blog.csdn.net/hjimce/article/details/50413257</a></p>
<p><a href="https://yq.aliyun.com/articles/68901" target="_blank" rel="noopener">https://yq.aliyun.com/articles/68901</a></p>
<p><a href="http://blog.csdn.net/luoming1994130/article/details/53523572" target="_blank" rel="noopener">http://blog.csdn.net/luoming1994130/article/details/53523572</a></p>
<p><img src="/2019/03/08/深度学习-基础篇/67.png" alt="67"></p>
<p><img src="/2019/03/08/深度学习-基础篇/68.png" alt="68"></p>
<p><img src="/2019/03/08/深度学习-基础篇/69.png" alt="69"></p>
<p><img src="/2019/03/08/深度学习-基础篇/70.png" alt="70"></p>
<p><img src="/2019/03/08/深度学习-基础篇/71.png" alt="71"></p>
<p><img src="/2019/03/08/深度学习-基础篇/72.png" alt="72"></p>
<h1>深度学习框架</h1>
<p><img src="/2019/03/08/深度学习-基础篇/50.png" alt="50"></p>
<h1>epoch</h1>
<p><a href="https://blog.csdn.net/qq_18668137/article/details/80883350" target="_blank" rel="noopener">https://blog.csdn.net/qq_18668137/article/details/80883350</a></p>
<h1>分类</h1>
<p>BP神经网络，LM神经网络，RBF径向基神经网络，FNN模糊神经网络，GMDH神经网络，ANFIS自适应神经网络，GRU，GRNN编码器，cnn，rnn，lstm</p>
<p>深度信念网络 Deep belief machines</p>
<p>HTM算法 Hierarchical temporal memory</p>
<p>堆叠自动编码器 Stacked Boltzmann Machine</p>
<p>生成式对抗网络 Generative adversarial networks</p>
<p>前馈神经网络 Feedforward neurral network</p>
<p>极端学习机 Extreme learning machine</p>
<p>逻辑学习机 Logic learning machine<a href="https://en.wikipedia.org/wiki/Logic_learning_machine" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Logic_learning_machine</a></p>
<p>自组织映射神经网络 Self-organizing map</p>
<p>自动编码器 Autoencoder</p>
<p>Hopfield网络 Hopfield network</p>
<p>多层感知器 Multilayer perceptron</p>
<p>径向基函数网络（RBFN） Radial basis function network</p>
<p>玻尔兹曼机 Boltzmann machine</p>
<p>受限玻尔兹曼机 Restricted Boltzmann machine</p>
<p>自组织映射（SOM） Self-organizing map</p>
<p>脉冲神经网络 Spiking neural network</p>
<h1>经典网络</h1>
<p>alexnet，vgg-net</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/数据挖掘-关联分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/数据挖掘-关联分析/" itemprop="url">数据挖掘-关联分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:42:06+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>关联分析：</p>
<p>apriori算法（最小支持度，最小置信度，项集，支持度计数）</p>
<p>FP-growth算法，FP-Tree，Eclat算法，灰色关联法</p>
<p>基于关联规则的分类</p>
<p>关联规则挖掘是数据挖掘中一个重要的研究领域。近年来，对于如何将关联规则挖掘用于分类问题，学者们进行了广泛的研究。关联分类方法挖掘形如condset-&gt;C的规则，其中condset是项(或属性值对)的集合，而C是类标号，这种形式的规则称为类关联规则(class association rules, CARS)。关联分类方法一般由两步组成:第一步用关联规则挖掘算法从训练数据集中挖掘出所有满足指定支持度和置信度的类关联规则;第二步使用启发式方法从挖掘出的类关联规则中挑选出一组高质量的规则用于分类。属于关联分类的算法主要包括CBA[44]，ADT，CMAR等。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/数据科学-基础知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/数据科学-基础知识/" itemprop="url">数据科学-基础知识</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:42:06+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1>基本概念</h1>
<p>输入空间，输出空间，可以是有限元素的集合，也可以是一个欧氏空间</p>
<p>每个具体的输入是一个实例，通常由特征向量表示，这时，所有特征向量存在的空间成为特征空间</p>
<p>假设空间：输入空间到输出空间的映射的集合</p>
<p>学习三要素：模型：确定模型空间，策略：确定模型空间中什么是好的模型，算法：在模型空间中怎么得到好的模型</p>
<h2 id="学习任务分类"><a class="header-anchor" href="#学习任务分类">¶</a>学习任务分类</h2>
<p>监督学习，无监督学习，半监督学习，强化学习，迁移学习/联邦学习</p>
<p>半监督学习：</p>
<p>生成模型 Generative models</p>
<p>低密度分离 Low-density separation</p>
<p>联合训练 Co-training</p>
<p>迁移学习 Transfer learning：</p>
<p>传递式迁移学习 Transitive Transfer Learning</p>
<h2 id="问题分类"><a class="header-anchor" href="#问题分类">¶</a>问题分类</h2>
<p>分类问题，标注问题，回归问题</p>
<h1>(优化)策略</h1>
<h2 id="损失函数"><a class="header-anchor" href="#损失函数">¶</a>损失函数</h2>
<p>损失函数度量模型一次预测的好坏</p>
<p>0-1损失函数，平方损失函数，绝对损失函数，对数损失函数（对数似然损失函数）</p>
<h2 id="风险函数"><a class="header-anchor" href="#风险函数">¶</a>风险函数</h2>
<p>风险函数度量平均意义下模型预测的好坏，也叫期望损失</p>
<p>经验风险（经验损失）</p>
<h2 id="经验风险最小化"><a class="header-anchor" href="#经验风险最小化">¶</a>经验风险最小化</h2>
<h2 id="结构风险最小化"><a class="header-anchor" href="#结构风险最小化">¶</a>结构风险最小化</h2>
<p>为了防止过拟合而提出的策略，等价于正则化</p>
<h1>模型评估</h1>
<h2 id="训练误差和测试误差"><a class="header-anchor" href="#训练误差和测试误差">¶</a>训练误差和测试误差</h2>
<h2 id="评价指标："><a class="header-anchor" href="#评价指标：">¶</a>评价指标：</h2>
<h3 id="绝对误差-相对误差"><a class="header-anchor" href="#绝对误差-相对误差">¶</a>绝对误差，相对误差</h3>
<h3 id="平均绝对误差-mean-absolute-error-mae"><a class="header-anchor" href="#平均绝对误差-mean-absolute-error-mae">¶</a>平均绝对误差（mean absolute error MAE）</h3>
<h3 id="均方误差-mean-squared-error-mse"><a class="header-anchor" href="#均方误差-mean-squared-error-mse">¶</a>均方误差（mean squared error MSE）</h3>
<h3 id="均方根误差-root-mean-squared-error-rmse"><a class="header-anchor" href="#均方根误差-root-mean-squared-error-rmse">¶</a>均方根误差（root mean squared error RMSE）</h3>
<h3 id="平均绝对百分误差-mean-absolute-percentage-error-mape"><a class="header-anchor" href="#平均绝对百分误差-mean-absolute-percentage-error-mape">¶</a>平均绝对百分误差（mean absolute percentage error MAPE）</h3>
<h3 id="kappa统计"><a class="header-anchor" href="#kappa统计">¶</a>Kappa统计</h3>
<h3 id="准确度accuracy-tp-tn-fp-fn"><a class="header-anchor" href="#准确度accuracy-tp-tn-fp-fn">¶</a>准确度accuracy（TP,TN,FP,FN）</h3>
<p>TPR = TP / (TP + FN)</p>
<p>FPR = PF / (FP + TN)</p>
<h3 id="识别准确率presion-召回率recall"><a class="header-anchor" href="#识别准确率presion-召回率recall">¶</a>识别准确率presion &amp;&amp; 召回率recall</h3>
<h3 id="混淆矩阵"><a class="header-anchor" href="#混淆矩阵">¶</a>混淆矩阵</h3>
<h3 id="mean-average-precision-map"><a class="header-anchor" href="#mean-average-precision-map">¶</a>Mean Average Precision (MAP)</h3>
<h3 id="auc-area-under-roc-curve-roc-receiver-operating-characteristic"><a class="header-anchor" href="#auc-area-under-roc-curve-roc-receiver-operating-characteristic">¶</a>AUC（Area Under roc Curve）&amp;&amp; ROC (Receiver Operating Characteristic)</h3>
<p><a href="https://blog.csdn.net/pipisorry/article/details/51788927" target="_blank" rel="noopener">https://blog.csdn.net/pipisorry/article/details/51788927</a></p>
<h3 id="f值-f-measure"><a class="header-anchor" href="#f值-f-measure">¶</a>F值（F-Measure）</h3>
<p>F = 2TP / (2TP + FP + FN)，精确率和召回率都高时，F值也会高</p>
<h3 id="a-b-test显著性检验"><a class="header-anchor" href="#a-b-test显著性检验">¶</a>A/B-test显著性检验</h3>
<h2 id="评估："><a class="header-anchor" href="#评估：">¶</a>评估：</h2>
<p>交叉验证，自助法，随机二次抽样</p>
<h1>过拟合/欠拟合：</h1>
<p>过拟合：把误差，噪声也拟合进去了</p>
<p>Errors on training data are small</p>
<p>But errors on new points are likely to be large</p>
<h2 id="正则化"><a class="header-anchor" href="#正则化">¶</a>正则化</h2>
<p>L1L2范数（模型参数向量的范数）</p>
<p>奥卡姆剃刀模型</p>
<h2 id="交叉验证"><a class="header-anchor" href="#交叉验证">¶</a>交叉验证</h2>
<p>训练集的划分</p>
<p>训练集，验证集，测试集</p>
<p>简单交叉验证</p>
<p>k折交叉验证</p>
<p>cv交叉验证</p>
<p>留一交叉验证</p>
<h2 id="dropout"><a class="header-anchor" href="#dropout">¶</a>dropout</h2>
<p><a href="https://blog.csdn.net/crazy_scott/article/details/80343324" target="_blank" rel="noopener">https://blog.csdn.net/crazy_scott/article/details/80343324</a></p>
<h1>泛化能力</h1>
<p>泛化误差上界，推导</p>
<h1>生成模型/判别模型</h1>
<h1>Bias-Variance Tradeoff</h1>
<p><img src="/2019/03/08/数据科学-基础知识/1.png" alt="1"></p>
<p><img src="/2019/03/08/数据科学-基础知识/2.png" alt="2"></p>
<p>高斯马尔科夫定理：</p>
<p>数据质量：</p>
<p>缺失值</p>
<p>异常值（3σ原则，箱形图分析）</p>
<p>一致性分析/检验</p>
<p>数据特征/探索性数据分析EDAhttps://www.cnblogs.com/shencc3/p/7851340.html：</p>
<p>分布分析</p>
<p>定性（条形图，饼图）</p>
<p>定量（求极差-分组-决定分点-列出频率分布表-绘出频率直方分布图）</p>
<p>对比分析</p>
<p>绝对数比较</p>
<p>相对数比较（结构相对数，比例相对数，比较相对数，强度相对数，计划完成程度相对数，动态相对数）</p>
<p>统计量分析</p>
<p>集中趋势度量（均值，中位数，总数）</p>
<p>离中趋势度量（极差，标准差，变异系数，四分位数间距）</p>
<p>周期性分析</p>
<p>共献度分析（帕累托法则，2/8定律）</p>
<p>相关性分析</p>
<p>绘制散点图，绘制散点图矩阵</p>
<p>相关系数：pearson相关系数，spearman秩相关系数，判定系数</p>
<h1>数据预处理</h1>
<p>数据清洗</p>
<p>缺失值处理</p>
<p>不处理</p>
<p>删除记录</p>
<p>插补（均值/中位数/众数，使用固定值，最近邻插补，回归方法，插值法）（拉格朗日，牛顿，hermite，分段，样条）</p>
<p>异常值处理</p>
<p>不处理，删除记录，视为缺失值，平均值修正</p>
<p>数据集成</p>
<p>实体识别（同名同义，异名同义，单位不统一）</p>
<p>冗余属性识别</p>
<p>数据变换</p>
<p>简单函数变化</p>
<p>数据规范化/标准化（最大-最小规范化，零-均值规范化，小数定标规范化，归一化）</p>
<p>连续属性离散化（等宽法，等频法，聚类法）</p>
<p>属性构造</p>
<p>小波变换</p>
<p>数据规约</p>
<p>属性规约（合并属性，逐步向前选择，逐步向后删除，决策树归纳，主成分分析）</p>
<p>数值规约（直方图，聚类，抽样，参数回归）</p>
<p>数据融合：</p>
<h1>异常点/离群点检测</h1>
<p><strong>异常检测 Anomaly detection</strong></p>
<p>离群点分类（从数据范围，从数据类型，从属性个数）</p>
<p>检测方法（基于统计，基于邻近度，基于密度，基于聚类）</p>
<p>基于统计（一元正态分布的离群点检测，混合模型xxxx，）</p>
<p>基于聚类（丢弃远离其他簇的小簇，基于原型的聚类）</p>
<p>OneClassSVM，IsolationForest，Local Outlier Factor(LOF)，基于高斯分布的方法</p>
<p><a href="https://blog.csdn.net/qq_15111861/article/details/81178085" target="_blank" rel="noopener">https://blog.csdn.net/qq_15111861/article/details/81178085</a></p>
<p><a href="https://blog.csdn.net/littlely_ll/article/details/68486537" target="_blank" rel="noopener">https://blog.csdn.net/littlely_ll/article/details/68486537</a></p>
<p>局部异常因子 Local outlier factor</p>
<p>离群点检测</p>
<h1>陷阱与挑战</h1>
<p>过拟合</p>
<p>维度灾难</p>
<p>泛化能力</p>
<h1>数据特征</h1>
<p>连续性/离散型</p>
<h1>检验</h1>
<p>out-of-sample testing 和 in-sample testing（out-of-sample 样本外，in-sample样本内）</p>
<p><a href="https://blog.csdn.net/occamo/article/details/84957692" target="_blank" rel="noopener">https://blog.csdn.net/occamo/article/details/84957692</a></p>
<p>Ground Truth翻译的意思是地面实况，放到机器学习里面，再抽象点可以把它理解为真值、真实的有效值或者是标准的答案</p>
<p>shallow learning</p>
<p>互信息</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/数据科学-数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/数据科学-数据集/" itemprop="url">数据科学-数据集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:42:06+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>图像分类数据集</h1>
<p>The MNIST Database ( <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a> ) 最流行的图像识别数据集，使用手写数字。它包括6万个示例和1万个示例的测试集。这通常是第一个进行图像识别的数据集</p>
<p>ImageNet ( <a href="http://image-net.org/" target="_blank" rel="noopener">http://image-net.org/</a> ) 根据WordNet层次结构组织的图像数据库(目前仅为名词)。层次结构的每个节点都由数百个图像描述。目前，该集合平均每个节点有超过500个图像(而且还在增加)</p>
<p>MS-COCO，COCO是一个大型的、丰富的物体检测，分割和字幕数据集</p>
<p>CIFAR-10，该数据集是图像分类的另一个数据集，它由10个类的60,000个图像组成（每个类在上面的图像中表示为一行）。总共有50,000个训练图像和10,000个测试图像。数据集分为6个部分：5个训练批次和1个测试批次，每批有10,000个图像</p>
<p>MIRFlickr-25K图像数据集 (Huiskes and Lew 2008)（It originally consists of 25,000 image samples collected from the Flickr website.Each image is annotated by one or more labels selected from 24 labels and some textual tags）</p>
<p>NUS-WIDE 图像数据集(Chua et al. 2009)（It contains 260,648 images from a public web image dataset. There are 81 ground truth concepts man- ually annotated for search evaluation）</p>
<h1>文本分类/nlp数据集</h1>
<p>Spam – Non Spam (<a href="http://www.esp.uem.es/jmgomez/smsspamcorpus/" target="_blank" rel="noopener">http://www.esp.uem.es/jmgomez/smsspamcorpus/</a>)</p>
<p>区分短信是否为垃圾邮件是一个有趣的问题。你需要构建一个分类器将短信进行分类</p>
<p>Twitter Sentiment Analysis (<a href="http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/" target="_blank" rel="noopener">http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/</a>)</p>
<p>该数据集包含 1578627 个分类推文，每行被标记为1的积极情绪，0位负面情绪。数据依次基于 Kaggle 比赛和 Nick Sanders 的分析</p>
<p>Yelp评论</p>
<p>这是Yelp为了学习目的而发布的一个开放数据集。它由数百万用户评论，商业属性和来自多个大都市地区的超过20万张照片组成。这是一个非常常用的全球NLP挑战数据集</p>
<p>Movie Review Data (<a href="http://www.cs.cornell.edu/People/pabo/movie-review-data/" target="_blank" rel="noopener">http://www.cs.cornell.edu/People/pabo/movie-review-data/</a>)这个网站提供了一系列的电影评论文件，这些文件标注了他们的总体情绪极性(正面或负面)或主观评价(例如，“两个半明星”)和对其主观性地位(主观或客观)或极性的标签</p>
<p>WordNetWordNet</p>
<p>WordNetWordNet是一个包含英文synsets的大型数据库。Synsets是同义词组，每个描述不同的概念。WordNet的结构使其成为NLP非常有用的工具</p>
<h1>推荐引擎数据集</h1>
<p>MovieLens ( <a href="https://grouplens.org/" target="_blank" rel="noopener">https://grouplens.org/</a> )</p>
<p>MovieLens是一个帮助人们查找电影的网站。它有成千上万的注册用户。他们进行自动内容推荐，推荐界面，基于标签的推荐页面等在线实验。这些数据集可供下载，可用于创建自己的推荐系统</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/数据科学-进阶知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/数据科学-进阶知识/" itemprop="url">数据科学-进阶知识</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:42:06+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>势函数法：</p>
<p>势函数主要用于确定分类面，其思想来源于物理。</p>
<p>势函数法基本思想</p>
<p>假设要划分属于两种类别ω1和ω2的模式样本，这些样本可看成是分布在n维模式空间中的点xk。</p>
<p>把属于ω1的点比拟为某种能源点，在点上，电位达到峰值。</p>
<p>随着与该点距离的增大，电位分布迅速减小，即把样本xk附近空间x点上的电位分布，看成是一个势函数K(x,xk)。</p>
<p>对于属于ω1的样本集群，其附近空间会形成一个&quot;高地&quot;，这些样本点所处的位置就是&quot;山头&quot;。</p>
<p>同理，用电位的几何分布来看待属于ω2的模式样本，在其附近空间就形成&quot;凹地&quot;。</p>
<p>只要在两类电位分布之间选择合适的等高线，就可以认为是模式分类的判别函数。</p>
<p><a href="http://www.cnblogs.com/huadongw/p/4106290.html" target="_blank" rel="noopener">http://www.cnblogs.com/huadongw/p/4106290.html</a></p>
<p>积累势函数</p>
<p>拉格朗日乘子法，奇异点，驻点</p>
<p>随机场，条件随机场，马尔可夫随机场</p>
<p>最大熵模型</p>
<p>模糊分类</p>
<p><strong>随机方法</strong></p>
<p>Boltzmann学习，模拟退火，遗传算法，蒙特卡洛方法</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/深度学习-LSTM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/深度学习-LSTM/" itemprop="url">深度学习-LSTM</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:41:18+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/计算机科学基础-数据结构/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/计算机科学基础-数据结构/" itemprop="url">计算机科学基础-数据结构</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:41:04+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>数组</h1>
<h1>栈</h1>
<h1>队列</h1>
<h1>链表</h1>
<p>双向链表，循环链表</p>
<h1>树</h1>
<p>二叉树，完全二叉树，B树，B+树，红黑树，二叉搜索树，van Emde Boas树</p>
<h1>哈希表/散列表</h1>
<h1>图</h1>
<h1>矩阵</h1>
<p>稀疏矩阵，三角矩阵</p>
<h1>堆</h1>
<p>堆，斐波那契堆</p>
<h1>不相交集合</h1>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/shell/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/shell/" itemprop="url">shell</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:40:45+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1>文件系统</h1>
<h2 id="pwd-查看当前目录路径"><a class="header-anchor" href="#pwd-查看当前目录路径">¶</a>pwd 查看当前目录路径</h2>
<h2 id="ls-显示目录内容"><a class="header-anchor" href="#ls-显示目录内容">¶</a>ls 显示目录内容</h2>
<h2 id="cd-目录跳转"><a class="header-anchor" href="#cd-目录跳转">¶</a>cd 目录跳转</h2>
<h2 id="mkdir-创建文件夹"><a class="header-anchor" href="#mkdir-创建文件夹">¶</a>mkdir 创建文件夹</h2>
<h2 id="touch-创建文件"><a class="header-anchor" href="#touch-创建文件">¶</a>touch 创建文件</h2>
<h2 id="rm-删除文件"><a class="header-anchor" href="#rm-删除文件">¶</a>rm 删除文件</h2>
<h2 id="mv-移动文件"><a class="header-anchor" href="#mv-移动文件">¶</a>mv 移动文件</h2>
<h2 id="cp-拷贝文件"><a class="header-anchor" href="#cp-拷贝文件">¶</a>cp 拷贝文件</h2>
<h2 id="cat-输出文件内容"><a class="header-anchor" href="#cat-输出文件内容">¶</a>cat 输出文件内容</h2>
<h2 id="chmod-给文件的属主分配权限"><a class="header-anchor" href="#chmod-给文件的属主分配权限">¶</a>chmod 给文件的属主分配权限</h2>
<h1>进程</h1>
<h2 id="ps-查询进程"><a class="header-anchor" href="#ps-查询进程">¶</a>ps 查询进程</h2>
<h2 id="kill-杀死进程"><a class="header-anchor" href="#kill-杀死进程">¶</a>kill 杀死进程</h2>
<h2 id="lsof-查看端口"><a class="header-anchor" href="#lsof-查看端口">¶</a>lsof 查看端口</h2>
<h2 id="top-持续监控进程-系统整体信息"><a class="header-anchor" href="#top-持续监控进程-系统整体信息">¶</a>top 持续监控进程/系统整体信息</h2>
<h1>网络</h1>
<h2 id="curl-下载命令"><a class="header-anchor" href="#curl-下载命令">¶</a>curl 下载命令</h2>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -o</span><br></pre></td></tr></table></figure>
<h2 id="scp-终端传输命令"><a class="header-anchor" href="#scp-终端传输命令">¶</a>scp 终端传输命令</h2>
<p>使用ssh连接和加密方式</p>
<h2 id="netstat-查看网络信息"><a class="header-anchor" href="#netstat-查看网络信息">¶</a>netstat 查看网络信息</h2>
<h1>vim</h1>
<h1>其他</h1>
<h2 id="clear-清除屏幕内容"><a class="header-anchor" href="#clear-清除屏幕内容">¶</a>clear 清除屏幕内容</h2>
<h2 id="history-查看命令历史"><a class="header-anchor" href="#history-查看命令历史">¶</a>history 查看命令历史</h2>
<h2 id="echo-输出命令"><a class="header-anchor" href="#echo-输出命令">¶</a>echo 输出命令</h2>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/算法刷题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/算法刷题/" itemprop="url">算法刷题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:40:45+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>LeetCode-1 Two Sum(Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice)</p>
<p>两遍哈希，一遍哈希</p>
<p>LeetCode-2. Add Two Numbers（You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list.）</p>
<p>初等数学遍历相加</p>
<p>LeetCode-3. Longest Substring Without Repeating Characters（Given a string, find the length of the longest substring without repeating characters）</p>
<p>滑动窗口</p>
<p>区分subsequence和substring</p>
<p>LeetCode-4. Median of Two Sorted Arrays（There are two sorted arrays <strong>nums1</strong> and <strong>nums2</strong> of size m and n respectively.Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n))）</p>
<p>递归</p>
<p>LeetCode-</p>
<p>LeetCode-46. Permutations（Given a collection of distinct integers, return all possible permutations）</p>
<p>递归</p>
<p>LeetCode:47. Permutations II</p>
<p>递归</p>
<p>LeetCode 50.Pow(x, n)</p>
<p>分治</p>
<p>Leetcode 69. Sqrt(x)</p>
<p>二分法</p>
<p>牛顿逼近</p>
<p>leetCode 93.Restore IP Addresses (恢复IP地址)</p>
<p>根据目前刷了这么多题，得出了两个经验，一是只要遇到字符串的子序列或配准问题首先考虑动态规划DP，二是只要遇到需要求出所有可能情况首先考虑用递归。</p>
<p>递归搜索</p>
<p>LeetCode-100 Same Tree（Given two binary trees, write a function to check if they are equal or not. Two binary trees are considered equal if they are structurally identical and the nodes have the same value）</p>
<p>遍历</p>
<p>Leetcode 104. Maximum Depth of Binary Tree（Given a binary tree, find its maximum depth）</p>
<p>递归，层序</p>
<p>LeetCode111（The minimum depth is the number of nodes along the shortest path from the root node down to the nearest leaf node）</p>
<p>层序遍历，记录遍历的层数，一旦我们遍历到第一个叶结点，就将当前层数返回</p>
<p>LeetCode126—Word Ladder II</p>
<p>BFS建立邻接表 从后往前搜索</p>
<p>若所有边的长度相等，广度优先搜索算法是最佳解——亦即它找到的第一个解，距离根节点的边数目一定最少</p>
<p>LeetCode127—Word Ladder</p>
<p>bfs</p>
<p>Leetcode128 Longest Consecutive Sequence solution（Given an unsorted array of integers, find the length of the longest consecutive elements sequence）</p>
<p>哈希表，set</p>
<p>LeetCode 129 Sum Root to Leaf Numbers</p>
<p>先序遍历，层序遍历</p>
<p>LeetCode 130 Surrounded Regions（Given a 2D board containing ‘X’ and ‘O’ (the letter O), capture all regions surrounded by ‘X’.）</p>
<p>搜索</p>
<p>leedcode 134 Gas Station（There are N gas stations along a circular route, where the amount of gas at station i is gas[i].You have a car with an unlimited gas tank and it costs cost[i] of gas to travel from station i to its next station (i+1). You begin the journey with an empty tank at one of the gas stations.Return the starting gas station’s index if you can travel around the circuit once, otherwise return -1）</p>
<p>贪心，start的后退，end的前进</p>
<p>LeetCode 135 Candy（There are N children standing in a line. Each child is assigned a rating value.You are giving candies to these children subjected to the following requirements:Each child must have at least one candy.Children with a higher rating get more candies than their neighbors.What is the minimum candies you must give?）</p>
<p>两次遍历（前，后）</p>
<p>LeetCode 136 single-number（Given an array of integers, every element appears twice except for one. Find that single one）</p>
<p>异或，哈希</p>
<p>LeetCode 137 single-number-ii（Given an array of integers, every element appears three times except for one. Find that single one）</p>
<p>位运算（妙解），哈希，排序</p>
<p>Leetcode138 Copy List with Random Pointer solution（A linked list is given such that each node contains an additional random pointer which could point to any node in the list or null.Return a deep copy of the list.）</p>
<p>插入节点，分离节点</p>
<p>LeetCode139 Word Break（Given a string s and a dictionary of words dict, determine if s can be segmented into a space-separated sequence of one or more dictionary words）</p>
<p>dp</p>
<p>leetcode141 Linked List Cycle（Given a linked list, determine if it has a cycle in it.Follow up: Can you solve it without using extra space?）</p>
<p>快慢指针</p>
<p>Leetcode 142 Linked List Cycle (II)（Given a linked list, return the node where the cycle begins. If there is no cycle, return null.Note: Do not modify the linked list.Follow up:Can you solve it without using extra space?）</p>
<p>快慢指针</p>
<p>快慢指针应用：</p>
<p>判断一个链表是否有环</p>
<p>求一个链表是否存在环，如果存在，则求出环的入口结点</p>
<p>求链表是否存在环的变式，如给定两个链表A和B，判断两个链表是否相交，解决方法就是将A链表尾节点指向头结点形成一个环，检测B链表是否存在环，如果存在，则两个链表相交，而检测出来的依赖环入口即为相交的第一个点</p>
<p>求有序链表中求出其中位数，这种问题也是设置快慢指针，当快指针到底链表尾部的时候，慢指针刚好指向链表中间的结点</p>
<p>LeetCode-143. Reorder List（Given a singly linked list L: L 0→L 1→…→L n-1→L n,reorder it to: L 0→L n →L 1→L n-1→L 2→L n-2→…You must do this in-place without altering the nodes’ values.）</p>
<p>快慢指针</p>
<p>LeetCode 144. Binary Tree Preorder Traversal（Given a binary tree, return the preorder traversal of its nodes’ values.Note: Recursive solution is trivial, could you do it iteratively?）</p>
<p>栈，递归</p>
<p>[leetcode]147. Insertion Sort List（Sort a linked list using insertion sort）</p>
<p>新建一个链表,遍历原链表，将每个节点加入新链表正确的位置</p>
<p>Leetcode 149 Max Points on a Line</p>
<p>穷举法，两边循环，找斜率</p>
<p>CV中的hough transform（据说不保证完全正确）</p>
<p>LeetCode 148. Sort List–O(nlogn)时间复杂度和常数空间复杂度给链表排序</p>
<p>归并排序和快慢指针</p>
<p>LeetCode150逆波兰表达式求解（Evaluate Reverse Polish Notation）</p>
<p>用栈</p>
<p>判断两个链表是否相交并找出交点</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/08/计算机科学基础-算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chenxr">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenxr's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/08/计算机科学基础-算法/" itemprop="url">计算机科学基础-算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-08T22:40:45+08:00">
                2019-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1>动态优化</h1>
<h1>搜索</h1>
<p>DFS，BFS，回溯</p>
<h1>查找</h1>
<p>二分，线性查找</p>
<h1>图</h1>
<p>Dijkstra，深度优先，广度优先，拓扑排序，强连通分量，最小生成树，最短路径，最大流</p>
<h1>贪心</h1>
<h1>分治</h1>
<p><a href="https://www.cnblogs.com/hellohacker/p/5827222.html" target="_blank" rel="noopener">https://www.cnblogs.com/hellohacker/p/5827222.html</a></p>
<h1>排序</h1>
<p>插入，选择，冒泡，希尔，快速，归并，堆，计数，桶，基数，外排序</p>
<p><img src="/2019/03/08/计算机科学基础-算法/1.png" alt="1"></p>
<h1>随机算法</h1>
<h1>摊还分析</h1>
<h1>多线程算法</h1>
<h1>矩阵运算</h1>
<h1>线性规划</h1>
<h1>多项式与快速傅里叶变换</h1>
<h1>数论算法</h1>
<h1>字符串</h1>
<p>模式匹配：KMP算法</p>
<h1>计算几何学</h1>
<h1>NP完全性</h1>
<h1>近似算法</h1>
<h1>大数问题</h1>
<p><a href="https://www.cnblogs.com/2228212230qq/p/7684472.html" target="_blank" rel="noopener">https://www.cnblogs.com/2228212230qq/p/7684472.html</a></p>
<p><a href="https://www.cnblogs.com/ganhang-acm/p/3860361.html" target="_blank" rel="noopener">https://www.cnblogs.com/ganhang-acm/p/3860361.html</a></p>
<p><a href="https://blog.csdn.net/xiang_6/article/details/80659769" target="_blank" rel="noopener">https://blog.csdn.net/xiang_6/article/details/80659769</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Chenxr</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">64</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chenxr</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
